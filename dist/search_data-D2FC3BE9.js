searchData={"items":[{"type":"module","title":"Anoma","doc":"Documentation for `Anoma`.","ref":"Anoma.html"},{"type":"function","title":"Anoma.hello/0","doc":"Hello world.","ref":"Anoma.html#hello/0"},{"type":"function","title":"Examples - Anoma.hello/0","doc":"iex> Anoma.hello()\n    :world","ref":"Anoma.html#hello/0-examples"},{"type":"function","title":"Anoma.start/2","doc":"","ref":"Anoma.html#start/2"},{"type":"function","title":"Anoma.start_logic/0","doc":"","ref":"Anoma.html#start_logic/0"},{"type":"module","title":"Anoma.Block","doc":"I represent a block that will be stored and gossiped around the\nnetwork.\n\n#","ref":"Anoma.Block.html"},{"type":"module","title":"Fields - Anoma.Block","doc":"- `:id` - Identification number derived from the serialization of my:\n      + digest(block)\n      + round\n      + pub_key\n   - `:block` - The block I contain\n   - `:round` - The round I come from\n   - `:pub_key` - Public key\n   - `:signature` - Id signed with the private_key related to my public_key","ref":"Anoma.Block.html#module-fields"},{"type":"function","title":"Anoma.Block.create/3","doc":"I create a block, if a private key is passed in my second parameter,\nthen I also contain a signature of myself.\n\nThe signature (if created), represents that my `:pub_key` signed my\n`:id`. This can be cryptography verified with `Serializer.verify`\n\n#","ref":"Anoma.Block.html#create/3"},{"type":"function","title":"Parameters - Anoma.Block.create/3","doc":"- `block` - the base block that I am structured around\n  - `key` - Either a public key or a public private key paring\n  - `round` - The round that I represent","ref":"Anoma.Block.html#create/3-parameters"},{"type":"function","title":"Anoma.Block.create_table/0","doc":"I create a `:mnesia` table for `Anoma.Block`. This table is backed\nby rocksdb, and thus persists across IEX sessions.\n\nI will only ever needed to be called once upon Configuration start,\n`Anoma.Mnesia.init/0` will likely set me up as is.","ref":"Anoma.Block.html#create_table/0"},{"type":"function","title":"Anoma.Block.create_table/2","doc":"I am like `create_table/0`, however I am given a special\ntable_key. This overrides the default table key of `Anoma.Block`.\n\nI am useful when trying to spawn many solvers/validators/etc, who\nall want their own tables.\n\n#","ref":"Anoma.Block.html#create_table/2"},{"type":"function","title":"Parameters - Anoma.Block.create_table/2","doc":"- `table_key` - the name of the table\n  - `rocks?` - should we persist as a rocksdb table?","ref":"Anoma.Block.html#create_table/2-parameters"},{"type":"function","title":"Anoma.Block.decode/1","doc":"","ref":"Anoma.Block.html#decode/1"},{"type":"function","title":"Anoma.Block.encode/1","doc":"","ref":"Anoma.Block.html#encode/1"},{"type":"function","title":"Anoma.Block.encode/2","doc":"","ref":"Anoma.Block.html#encode/2"},{"type":"function","title":"Anoma.Block.sign/2","doc":"I sign my id given a private key. I do no validation checking if the\n`id` is derived properly.","ref":"Anoma.Block.html#sign/2"},{"type":"type","title":"Anoma.Block.private_key/0","doc":"","ref":"Anoma.Block.html#t:private_key/0"},{"type":"type","title":"Anoma.Block.public_key/0","doc":"","ref":"Anoma.Block.html#t:public_key/0"},{"type":"type","title":"Anoma.Block.t/0","doc":"","ref":"Anoma.Block.html#t:t/0"},{"type":"module","title":"Anoma.Block.Base","doc":"I represent the Base part of a block.\n\n#","ref":"Anoma.Block.Base.html"},{"type":"module","title":"Type - Anoma.Block.Base","doc":"- `:transactions` - A list of transactions.","ref":"Anoma.Block.Base.html#module-type"},{"type":"function","title":"Anoma.Block.Base.default/0","doc":"","ref":"Anoma.Block.Base.html#default/0"},{"type":"function","title":"Anoma.Block.Base.digest/1","doc":"","ref":"Anoma.Block.Base.html#digest/1"},{"type":"function","title":"Anoma.Block.Base.new/1","doc":"","ref":"Anoma.Block.Base.html#new/1"},{"type":"type","title":"Anoma.Block.Base.t/0","doc":"","ref":"Anoma.Block.Base.html#t:t/0"},{"type":"module","title":"Anoma.Cli","doc":"","ref":"Anoma.Cli.html"},{"type":"function","title":"Anoma.Cli.argument_parser/0","doc":"","ref":"Anoma.Cli.html#argument_parser/0"},{"type":"function","title":"Anoma.Cli.main/1","doc":"","ref":"Anoma.Cli.html#main/1"},{"type":"module","title":"Anoma.Configuration","doc":"I am a configuration module. I read the provided TOML configuration file\nand feed the apporpriate info for Node launching\n\nThe codebase has a corresponding file that can inform the user of the\nformat I expect.\n\n#","ref":"Anoma.Configuration.html"},{"type":"module","title":"Public API - Anoma.Configuration","doc":"- `launch_min/1`\n- `parse_node/1`\n- `parse/1`","ref":"Anoma.Configuration.html#module-public-api"},{"type":"function","title":"Anoma.Configuration.launch_min/1","doc":"Given a file path to a TOML file with minimal node startup I launch the\nnode with the appopriate name","ref":"Anoma.Configuration.html#launch_min/1"},{"type":"function","title":"Anoma.Configuration.parse/1","doc":"I decode the TOML file provided a path to it, ignoring if\nunsuccesful","ref":"Anoma.Configuration.html#parse/1"},{"type":"function","title":"Anoma.Configuration.parse_min/1","doc":"Given a map, I decode all the needed info for a minimal node startup\nand put it in the appropriate keyword list","ref":"Anoma.Configuration.html#parse_min/1"},{"type":"module","title":"Anoma.Dump","doc":"I provide an interface to dump current state and load appropriate\nexternal files to launch them as Anoma nodes.\n\nYou can also use me to dump info such as current states and tables\nin a readable map format as well as get info stored in external\nfiles in binary format.\n\n#","ref":"Anoma.Dump.html"},{"type":"module","title":"Dumping API - Anoma.Dump","doc":"I give access to following public dumping functionality:\n\n- `dump/2`\n- `get_all/1`\n- `get_state/1`\n- `get_tables/1`\n\n#","ref":"Anoma.Dump.html#module-dumping-api"},{"type":"module","title":"Loading API - Anoma.Dump","doc":"I give access to following public loading functionality\n\n- `launch/2`\n- `load/1`","ref":"Anoma.Dump.html#module-loading-api"},{"type":"function","title":"Anoma.Dump.dump/2","doc":"I dump the current state with storage. I accept a string as a name,\nso that the resulting file will be created as name.txt and then a\nnode whose info presented as a map I dump as a binary.\n\nThe map typing can be seen in `get_all`","ref":"Anoma.Dump.html#dump/2"},{"type":"function","title":"Anoma.Dump.get_all/1","doc":"I get all the info on the node tables and engines in order:\n- router\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor\n- table names\n- qualified\n- order\n- block_storage\nAnd turn the info into a tuple","ref":"Anoma.Dump.html#get_all/1"},{"type":"function","title":"Anoma.Dump.get_state/1","doc":"I get the engine states in order:\n- router\n- mempool topic\n- executor topic\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor","ref":"Anoma.Dump.html#get_state/1"},{"type":"function","title":"Anoma.Dump.get_tables/1","doc":"I get the node tables in order:\n- storage (names)\n- qualified\n- order\n- block_storage","ref":"Anoma.Dump.html#get_tables/1"},{"type":"function","title":"Anoma.Dump.launch/2","doc":"I launch a node given a file containing a binary version of an 12-tuple\nwith appropriate info in the following order:\n- router id\n- mempool topic id\n- executor topic id\n- logger\n- clock\n- ordering\n- mempool\n- pinger\n- executor\n- storage names\n- qualified\n- order\n- block_storage\n\nAll engines have info on their states and id's so that checkpointing\nthe system will keep all adresses used in the previous session.\nNote that I ensure that the apporpriate tables\nare new.\n\nCheck whether your transactions have had an assigned worker. If not,\nrelaunch them directly.","ref":"Anoma.Dump.html#launch/2"},{"type":"function","title":"Anoma.Dump.load/1","doc":"I read the given file which I assume contains binary info and convert\nit to an Elixir term.\n\nAs the dumped state may have extra atoms not present in the session,\nI currently allow for atom creation in the loaded term.","ref":"Anoma.Dump.html#load/1"},{"type":"type","title":"Anoma.Dump.clock_eng/0","doc":"","ref":"Anoma.Dump.html#t:clock_eng/0"},{"type":"type","title":"Anoma.Dump.ex_eng/0","doc":"","ref":"Anoma.Dump.html#t:ex_eng/0"},{"type":"type","title":"Anoma.Dump.log_eng/0","doc":"","ref":"Anoma.Dump.html#t:log_eng/0"},{"type":"type","title":"Anoma.Dump.mem_eng/0","doc":"","ref":"Anoma.Dump.html#t:mem_eng/0"},{"type":"type","title":"Anoma.Dump.ord_eng/0","doc":"","ref":"Anoma.Dump.html#t:ord_eng/0"},{"type":"type","title":"Anoma.Dump.ping_eng/0","doc":"","ref":"Anoma.Dump.html#t:ping_eng/0"},{"type":"type","title":"Anoma.Dump.stores/0","doc":"","ref":"Anoma.Dump.html#t:stores/0"},{"type":"protocol","title":"Anoma.Intent","doc":"I am an Intent, I give off the behavior of how Intents can be used.\n\nCurrently there are two kinds of objects which implement me:\n\n1. Anoma.Resource\n2. Anoma.PartialTx\n\nMore can be found on my API.","ref":"Anoma.Intent.html"},{"type":"function","title":"Anoma.Intent.is_intent/1","doc":"","ref":"Anoma.Intent.html#is_intent/1"},{"type":"type","title":"Anoma.Intent.t/0","doc":"All the types that implement this protocol.","ref":"Anoma.Intent.html#t:t/0"},{"type":"module","title":"Anoma.Node.Clock","doc":"I am the implmentation of the Local Wall Clock Engine.\n\nI provide info on the time elapsed in milliseconds after the node launched\nand the epoch from which it has been calculated using monotonic time.","ref":"Anoma.Node.Clock.html"},{"type":"function","title":"Anoma.Node.Clock.get_epoch/1","doc":"","ref":"Anoma.Node.Clock.html#get_epoch/1"},{"type":"function","title":"Anoma.Node.Clock.get_time/1","doc":"","ref":"Anoma.Node.Clock.html#get_time/1"},{"type":"function","title":"Anoma.Node.Clock.handle_call/3","doc":"","ref":"Anoma.Node.Clock.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Clock.init/1","doc":"","ref":"Anoma.Node.Clock.html#init/1"},{"type":"function","title":"Anoma.Node.Clock.state/1","doc":"","ref":"Anoma.Node.Clock.html#state/1"},{"type":"type","title":"Anoma.Node.Clock.t/0","doc":"","ref":"Anoma.Node.Clock.html#t:t/0"},{"type":"module","title":"Anoma.Node.Logger","doc":"I am a logging engine. I have a storage field which accepts the\nstorage used for the logging tied to a specific node, the number\nof messages which get stored per engine, as well as the name of\nthe clock used for timestamping.","ref":"Anoma.Node.Logger.html"},{"type":"function","title":"Anoma.Node.Logger.add/3","doc":"","ref":"Anoma.Node.Logger.html#add/3"},{"type":"function","title":"Anoma.Node.Logger.get/1","doc":"","ref":"Anoma.Node.Logger.html#get/1"},{"type":"function","title":"Anoma.Node.Logger.get/2","doc":"","ref":"Anoma.Node.Logger.html#get/2"},{"type":"function","title":"Anoma.Node.Logger.handle_call/3","doc":"","ref":"Anoma.Node.Logger.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Logger.handle_cast/3","doc":"","ref":"Anoma.Node.Logger.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Logger.init/1","doc":"","ref":"Anoma.Node.Logger.html#init/1"},{"type":"function","title":"Anoma.Node.Logger.state/1","doc":"","ref":"Anoma.Node.Logger.html#state/1"},{"type":"type","title":"Anoma.Node.Logger.t/0","doc":"","ref":"Anoma.Node.Logger.html#t:t/0"},{"type":"module","title":"Anoma.Node.Pinger","doc":"I provide periodic block execution based on submitted mempool name and time.","ref":"Anoma.Node.Pinger.html"},{"type":"function","title":"Anoma.Node.Pinger.handle_call/3","doc":"","ref":"Anoma.Node.Pinger.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Pinger.handle_info/2","doc":"","ref":"Anoma.Node.Pinger.html#handle_info/2"},{"type":"function","title":"Anoma.Node.Pinger.init/1","doc":"","ref":"Anoma.Node.Pinger.html#init/1"},{"type":"function","title":"Anoma.Node.Pinger.pinger/1","doc":"I send the :execute message after specified time if ever.","ref":"Anoma.Node.Pinger.html#pinger/1"},{"type":"function","title":"Anoma.Node.Pinger.set_timer/2","doc":"Given a server S and time T I change the timer set for the struct\nconnected to S setting it to T. Set T to :no_timer to stop the\npinger.","ref":"Anoma.Node.Pinger.html#set_timer/2"},{"type":"function","title":"Anoma.Node.Pinger.start/1","doc":"","ref":"Anoma.Node.Pinger.html#start/1"},{"type":"function","title":"Anoma.Node.Pinger.state/1","doc":"","ref":"Anoma.Node.Pinger.html#state/1"},{"type":"type","title":"Anoma.Node.Pinger.t/0","doc":"","ref":"Anoma.Node.Pinger.html#t:t/0"},{"type":"module","title":"Anoma.Node.Router","doc":"I have a few use cases and APIs throughout an Anoma application:\n\n1. I provide central routing infrastructure for inter-node and\n   intra-node communication\n\n1. I provide service's for topic creation and\n   `Anoma.Node.Router.Engine` creation\n\n1. I provide a behavior interface similar to `GenServer` for both\n   [`Engine`](`Anoma.Node.Router.Engine`) messaging and `Topic`\n   messaging","ref":"Anoma.Node.Router.html"},{"type":"module","title":"Router Topology - Anoma.Node.Router","doc":"A good view of my topology and how various\n`Anoma.Node.Router.Engine` and topic's relate to me can be seen by\nthe following diagram.\n\n```mermaid\ngraph TB\n  S(Router Supervisor)\n  R(Router)\n  C(Engine #1) ~~~ B(Engine #2)\n  T1(Topic #1) ~~~ T2(Topic #2)\n  S ==>R & B & C\n  S -.->T1 & T2\n  R <-->|router| B & C & T1 & T2\n```\n\n`Anoma.Node.Router.Engine`'s that are spawned via `start_engine/3`\nare added to the supervisor, and messages sent via `call/3` or\n`cast/2` may be routed through myself.\n\nTopics are handled somewhat specially. Since they serve a much more\nlimited role, I handle and manage them personally and the dashed\nlines in the diagram are not real. However for building a conceptual\nmodel, we can view `Topics` spawned by `new_topic/1` as spawning an\n[`Engine`](`Anoma.Node.Router.Engine`), and messages sent via\n`call/3` or `cast/2` as being routed through myself.","ref":"Anoma.Node.Router.html#module-router-topology"},{"type":"module","title":"Server Terminology - Anoma.Node.Router","doc":"For the sake of this document, the word `Server` will refer to both\n[`Engines`](`Anoma.Node.Router.Engine`) and `Topics`.","ref":"Anoma.Node.Router.html#module-server-terminology"},{"type":"module","title":"Router PIDs - Anoma.Node.Router","doc":"The IDs of the various topics and\n[engines](`Anoma.Node.Router.Engine`), are not regular Erlang\nPID's. Instead we use our own address schema laid out in\n`Anoma.Node.Router.Addr`. Further information can also be found in\nour specs (link to specs when they are online).","ref":"Anoma.Node.Router.html#module-router-pids"},{"type":"module","title":"Router API - Anoma.Node.Router","doc":"I offer an API for anyone wishing to call me. These functions are:\n\n- `start/0`\n- `start/1`\n- `new_topic/1`\n- `start_engine/3`\n- `start_engine/4`\n- `subscribe_topic/2`\n- `subscribe_topic/3`","ref":"Anoma.Node.Router.html#module-router-api"},{"type":"module","title":"Server APIs - Anoma.Node.Router","doc":"When writing server code, My module acts as a `GenServer` behavior,\nin that one should be using these functions when writing code to\ntalk to the `Server`:\n\n- `call/2`\n- `call/3`\n- `cast/2`\n\nThe API I offer is very reminiscent of `GenServer`'s API, however\nplease read the [examples](#module-examples) section to get a sense\non how the server code differs.","ref":"Anoma.Node.Router.html#module-server-apis"},{"type":"module","title":"Client/Server APIs - Anoma.Node.Router","doc":"Much like `GenServer`, user's typically don't call my `call/3` or\n`cast/2` directly. Instead the user wraps the calls in new functions\nrepresenting the public API of the server. These wrappers are called\nthe **client API**.\n\n#","ref":"Anoma.Node.Router.html#module-client-server-apis"},{"type":"module","title":"Examples - Anoma.Node.Router","doc":"To get a good feel for writing idiomatic code using me, and how my\nAPI is differs from `GenServer`, we will look at an implementation\nof a stack and see how it [differs from GenServer's stack\nexample](https://hexdocs.pm/elixir/GenServer.html#module-client-server-apis)\n\n    defmodule Stack do\n      alias Anoma.Node.Router\n\n      use Router.Engine\n\n      @spec init(String.t()) :: {:ok, list(String.t())}\n      def init(elements) do\n        initial_state = String.split(elements, \",\", trim: true)\n        {:ok, initial_state}\n      end\n\n      @spec push(Router.addr(), String.t()) :: :ok\n      def push(pid, element) do\n        Router.cast(pid, {:push, element})\n      end\n\n      @spec pop(Addr.t()) :: String.t()\n      def pop(pid) do\n        Router.call(pid, :pop)\n      end\n\n      def handle_call(:pop, _from, state) do\n        [to_caller | new_state] = state\n        {:reply, to_caller, new_state}\n      end\n\n      def handle_cast({:push, element}, _from, state) do\n        new_state = [element | state]\n        {:noreply, new_state}\n      end\n    end\n\nAnd we can use this Engine like the following\n\n    iex> {:ok, router} = Router.start()\n    iex> {:ok, stack} = Router.start_engine(router, Stack, \"hello\")\n    iex> Stack.pop(stack)\n    \"hello\"\n    iex> Stack.push(stack, \"hi\")\n    :ok\n    iex> Stack.pop(stack)\n    \"hi\"\n\nOverall having both server and client functionality that is clearly\nlabeled, leads to good user UI's.\n\n#","ref":"Anoma.Node.Router.html#module-examples"},{"type":"module","title":"Difference in Design from `GenServer` - Anoma.Node.Router","doc":"The Stack example shows how my API differs from `Genserver`:\n\n1. There is currently no `GenServer.start_link/3` for the Router\n\n1. Even `handle_cast`'s take a `from` parameter\n\n1. We use `Anoma.Node.Router.Engine` and not `GenServer`\n\n1. Further `call/2` by default has an :infinite timeout\n\n#","ref":"Anoma.Node.Router.html#module-difference-in-design-from-genserver"},{"type":"module","title":"Summarizing the interactions between Server and Clients - Anoma.Node.Router","doc":"For basic `Server`'s we can summarize interactions between all\nparties as follows.\n\n  ```mermaid\n  sequenceDiagram\n    participant C as Client (Process/Engine)\n    participant R as Router (Engine)\n    participant S as Server (Engine)\n    participant M as Module (Code)\n\n    note right of C: Typically started by an init process\n    C->>+R: Router.start_engine(router, module, arg, options)\n    R->>+S: GenServer.start_link(router, module, arg, options)\n    S-->>+M: init(arg)\n    M-->>-S: {:ok, state} | :ignore | {:error, reason}\n    S->>-R: {:ok, addr} | :ignore | {:error, reason}\n    R->>-C: {:ok, addr} | :ignore | {:error, reason}\n\n    note right of C: call is synchronous\n    C->>+R: Router.call(addr, message)\n    note right of R: For known engines this is optimized away\n    R->>+S: GenSever.call(pid, {self, message})\n    S-->>+M: handle_call(message, from, state)\n    M-->>-S: {:reply, reply, state} | {:stop, reason, reply, state}\n    S->>-C: reply\n\n    note right of C: cast is asynchronous\n    C-)R: Router.cast(addr, message)\n    note right of R: For known engines this is optimized away\n    R-)S: GenServer.cast(pid, message)\n    S-->>+M: handle_cast(message, state)\n    M-->>-S: {:noreply, state} | {:stop, reason, state}\n\n    note right of C: send is asynchronous. the PAID must be known\n    C-)S: Kernel.send(pid, message)\n    S-->>+M: handle_info(message, state)\n    M-->>-S: {:noreply, state} | {:stop, reason, state}\n```\n\nWhat this diagram doesn't show is how Topic messaging works, and for\nthat, this diagram may be of assistance.\n\n  ```mermaid\n  sequenceDiagram\n    participant C as Client (Process/Engine)\n    participant S2 as Server2 (Engine)\n    participant R as Router (Engine)\n    participant T as Topic (Topic)\n    participant S as Server (Engine)\n\n\n    note right of R: For simplicity we do not display a client\n    S2-)+R: GenServer.subscribe(router, topic)\n    R-->>+T: GenSever.call(addr, {self, message})\n    T-->>-R: :ok | {:error, :no_such_topic}\n    R-)-S2: :ok | {:error, :no_such_topic}\n\n\n    note right of C: cast is asynchronous\n    C-)R: Router.cast(addr, message)\n    R-)+S: GenServer.cast(pid, message)\n    note right of S: Imagine this call sends an update to a topic\n    S-)-R: Router.cast(topic_addr, msg)\n    R-->>T: Genserver.cast(pid, msg)\n    T-->>R: Router.cast(addr_S2, msg)\n    R-)S2: Genserver.cast(pid, msg)\n```\n\nThe dotted lines in the diagram are theoretically how `Tasks` could\nbe implemented, however this is implementation dependent, and does\nindeed differ from the diagram.","ref":"Anoma.Node.Router.html#module-summarizing-the-interactions-between-server-and-clients"},{"type":"function","title":"Anoma.Node.Router.call/2","doc":"See `call/3` for documentation.","ref":"Anoma.Node.Router.html#call/2"},{"type":"function","title":"Anoma.Node.Router.call/3","doc":"Makes a synchronous call to the `Server` and waits for a reply.\n\nCall has a few interesting cases we can consider\n\n1. Calling a local [`Engine`](`Anoma.Node.Router.Engine`)\n\n1. Calling a non local [`Engine`](`Anoma.Node.Router.Engine`)\n\nWe can not `call/3` a `Topic`, and thus those instances are not\nhandled.\n\nCurrently we do not handle the non local\n[`Engine`](`Anoma.Node.Router.Engine`) case.\n\nFor the local [`Engine`](`Anoma.Node.Router.Engine`), then their\n[`Engine.handle_call/3`](`c:Anoma.Node.Router.Engine.handle_call/3`)\nwill be called on the [`Engine`](`Anoma.Node.Router.Engine`) to\nhandle the request.\n\n#","ref":"Anoma.Node.Router.html#call/3"},{"type":"function","title":"Timeouts - Anoma.Node.Router.call/3","doc":"By default the timeout is infinite for local calls. For non local\ncalls the timeout is not yet defined and will be iterated upon in\nfuture versions","ref":"Anoma.Node.Router.html#call/3-timeouts"},{"type":"function","title":"Anoma.Node.Router.cast/2","doc":"Makes a synchronous call to the `Server` and waits for a reply.\n\nCall has a few interesting cases we can consider\n\n1. Casting to a local [`Engine`](`Anoma.Node.Router.Engine`)\n\n1. Calling to a non local [`Engine`](`Anoma.Node.Router.Engine`)\n\n1. Casting to a `Topic`\n\n\nFor the local [`Engine`](`Anoma.Node.Router.Engine`), then their\n[`Engine.handle_cast/3`](`c:Anoma.Node.Router.Engine.handle_cast/3`)\nwill be called on the [`Engine`](`Anoma.Node.Router.Engine`) to\nhandle the request.\n\nCalling a non local [`Engine`](`Anoma.Node.Router.Engine`) isn't\nhandled yet.\n\nFor `Topics` any `cast/2` sent, then triggers a series of `cast/2`\nto all subscribed `Process`'s","ref":"Anoma.Node.Router.html#cast/2"},{"type":"function","title":"Anoma.Node.Router.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Router.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Router.handle_self_call/3","doc":"","ref":"Anoma.Node.Router.html#handle_self_call/3"},{"type":"function","title":"Anoma.Node.Router.init/1","doc":"","ref":"Anoma.Node.Router.html#init/1"},{"type":"function","title":"Anoma.Node.Router.new_topic/1","doc":"Creates a new topic. Takes the address of the router.","ref":"Anoma.Node.Router.html#new_topic/1"},{"type":"function","title":"Anoma.Node.Router.new_topic/2","doc":"","ref":"Anoma.Node.Router.html#new_topic/2"},{"type":"function","title":"Anoma.Node.Router.process_name/2","doc":"","ref":"Anoma.Node.Router.html#process_name/2"},{"type":"function","title":"Anoma.Node.Router.self_addr/1","doc":"","ref":"Anoma.Node.Router.html#self_addr/1"},{"type":"function","title":"Anoma.Node.Router.start/0","doc":"Starts a new router, with a random `Anoma.Crypto.Id`.","ref":"Anoma.Node.Router.html#start/0"},{"type":"function","title":"Anoma.Node.Router.start/1","doc":"Starts a new router with a given cryptographic ID.","ref":"Anoma.Node.Router.html#start/1"},{"type":"function","title":"Anoma.Node.Router.start_engine/3","doc":"","ref":"Anoma.Node.Router.html#start_engine/3"},{"type":"function","title":"Anoma.Node.Router.start_engine/4","doc":"Starts a new Engine","ref":"Anoma.Node.Router.html#start_engine/4"},{"type":"function","title":"Anoma.Node.Router.start_link/1","doc":"","ref":"Anoma.Node.Router.html#start_link/1"},{"type":"function","title":"Anoma.Node.Router.stop/1","doc":"","ref":"Anoma.Node.Router.html#stop/1"},{"type":"type","title":"Anoma.Node.Router.addr/0","doc":"","ref":"Anoma.Node.Router.html#t:addr/0"},{"type":"type","title":"Anoma.Node.Router.t/0","doc":"","ref":"Anoma.Node.Router.html#t:t/0"},{"type":"module","title":"Anoma.Node.Router.Addr","doc":"An address to which we can send a message.\nThe server, if known, is a local actor which can receive it directly;\n  otherwise, the mssage will be sent via the central router.\nIf the server is known, but the id is not, then this is a local-only\n  engine, which can only talk to other local engines.\n(Hence, at least one of id and server must be known; potentially both are.)","ref":"Anoma.Node.Router.Addr.html"},{"type":"type","title":"Anoma.Node.Router.Addr.t/0","doc":"","ref":"Anoma.Node.Router.Addr.html#t:t/0"},{"type":"behaviour","title":"Anoma.Node.Router.Engine","doc":"","ref":"Anoma.Node.Router.Engine.html"},{"type":"function","title":"Anoma.Node.Router.Engine.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Router.Engine.html#child_spec/1"},{"type":"callback","title":"Anoma.Node.Router.Engine.handle_call/3","doc":"","ref":"Anoma.Node.Router.Engine.html#c:handle_call/3"},{"type":"callback","title":"Anoma.Node.Router.Engine.handle_cast/3","doc":"","ref":"Anoma.Node.Router.Engine.html#c:handle_cast/3"},{"type":"function","title":"Anoma.Node.Router.Engine.handle_continue/2","doc":"","ref":"Anoma.Node.Router.Engine.html#handle_continue/2"},{"type":"function","title":"Anoma.Node.Router.Engine.init/1","doc":"","ref":"Anoma.Node.Router.Engine.html#init/1"},{"type":"function","title":"Anoma.Node.Router.Engine.start_link/1","doc":"","ref":"Anoma.Node.Router.Engine.html#start_link/1"},{"type":"type","title":"Anoma.Node.Router.Engine.from/0","doc":"","ref":"Anoma.Node.Router.Engine.html#t:from/0"},{"type":"type","title":"Anoma.Node.Router.Engine.t/0","doc":"","ref":"Anoma.Node.Router.Engine.html#t:t/0"},{"type":"module","title":"Anoma.Serializer","doc":"I aspire to give a language independent serialization format for any\nerlang/elixir type. Further, I handle hashing and digesting the\nterms as well!\n\nFor the time being, Ι just use the basic erlang only technique,\nplease improve me!","ref":"Anoma.Serializer.html"},{"type":"function","title":"Anoma.Serializer.deserialize/1","doc":"I `deserialize` the given object back into an erlang term.","ref":"Anoma.Serializer.html#deserialize/1"},{"type":"function","title":"Anoma.Serializer.digest/1","doc":"","ref":"Anoma.Serializer.html#digest/1"},{"type":"function","title":"Anoma.Serializer.serialize/1","doc":"","ref":"Anoma.Serializer.html#serialize/1"},{"type":"function","title":"Anoma.Serializer.sign/2","doc":"I `deserialize` the given object back into an erlang term.","ref":"Anoma.Serializer.html#sign/2"},{"type":"function","title":"Anoma.Serializer.verify/3","doc":"","ref":"Anoma.Serializer.html#verify/3"},{"type":"type","title":"Anoma.Serializer.private_key/0","doc":"","ref":"Anoma.Serializer.html#t:private_key/0"},{"type":"type","title":"Anoma.Serializer.public_key/0","doc":"","ref":"Anoma.Serializer.html#t:public_key/0"},{"type":"module","title":"Anoma.Transaction","doc":"I represent an Anoma Transaction\n\nI can be viewed as a wrapper over `Anoma.Intent` where I contain the\nintents used in a transaction","ref":"Anoma.Transaction.html"},{"type":"function","title":"Anoma.Transaction.id/1","doc":"","ref":"Anoma.Transaction.html#id/1"},{"type":"function","title":"Anoma.Transaction.new/3","doc":"","ref":"Anoma.Transaction.html#new/3"},{"type":"function","title":"Anoma.Transaction.pid/1","doc":"","ref":"Anoma.Transaction.html#pid/1"},{"type":"function","title":"Anoma.Transaction.transaction/1","doc":"","ref":"Anoma.Transaction.html#transaction/1"},{"type":"type","title":"Anoma.Transaction.execution/0","doc":"","ref":"Anoma.Transaction.html#t:execution/0"},{"type":"type","title":"Anoma.Transaction.t/0","doc":"","ref":"Anoma.Transaction.html#t:t/0"},{"type":"module","title":"Livebook","doc":"I generate out extra information for Livebook\n\nMy main purpose is to generate out the TOC for each livebook\ndocument we have.\n\nto do this please run `toc_toplevel/0`","ref":"Livebook.html"},{"type":"module","title":"API - Livebook","doc":"- `toc_toplevel/0`\n- `get_all_livemd_documents/0`\n- `example_toc/0`","ref":"Livebook.html#module-api"},{"type":"function","title":"Livebook.add_heading_num/1","doc":"","ref":"Livebook.html#add_heading_num/1"},{"type":"function","title":"Livebook.change_header/4","doc":"I replace the header with the given TOC\n\n#","ref":"Livebook.html#change_header/4"},{"type":"function","title":"Example - Livebook.change_header/4","doc":"> markdown_text = \"","ref":"Livebook.html#change_header/4-example"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"text here","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\"\n  > Livebook.change_header(markdown_text, \"##\", \"Index\", \"New Content\") |> IO.puts","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Intro ... - Livebook.change_header/4","doc":"","ref":"Livebook.html#change_header/4-intro"},{"type":"function","title":"Index - Livebook.change_header/4","doc":"New Content","ref":"Livebook.html#change_header/4-index"},{"type":"function","title":"Conclusion - Livebook.change_header/4","doc":"All good\n    :ok","ref":"Livebook.html#change_header/4-conclusion"},{"type":"function","title":"Livebook.count_depth/1","doc":"","ref":"Livebook.html#count_depth/1"},{"type":"function","title":"Livebook.dir_from_path/1","doc":"","ref":"Livebook.html#dir_from_path/1"},{"type":"function","title":"Livebook.example_toc/0","doc":"I provide an example of what a TOC looks like","ref":"Livebook.html#example_toc/0"},{"type":"function","title":"Livebook.generate_heading/4","doc":"","ref":"Livebook.html#generate_heading/4"},{"type":"function","title":"Livebook.generate_TOC/2","doc":"Generates out a TOC, given a series of nested documents\n\nWe take a path, and a place where we should be calculating the TOC from.","ref":"Livebook.html#generate_TOC/2"},{"type":"function","title":"Example - Livebook.generate_TOC/2","doc":"","ref":"Livebook.html#generate_TOC/2-example"},{"type":"function","title":"Livebook.get_all_livemd_documents/0","doc":"I get out all live view docs","ref":"Livebook.html#get_all_livemd_documents/0"},{"type":"function","title":"Livebook.get_livemd_documents/1","doc":"Gets all livemd documents in a sorted list given a path.","ref":"Livebook.html#get_livemd_documents/1"},{"type":"function","title":"Livebook.inject_TOC/2","doc":"","ref":"Livebook.html#inject_TOC/2"},{"type":"function","title":"Livebook.toc_toplevel/0","doc":"I generate out the TOC for all liveview docs","ref":"Livebook.html#toc_toplevel/0"},{"type":"task","title":"mix toc","doc":"I generate out the TOC for each liveview doc","ref":"Mix.Tasks.Toc.html"},{"type":"function","title":"Mix.Tasks.Toc.run/1","doc":"","ref":"Mix.Tasks.Toc.html#run/1"},{"type":"module","title":"Anoma.Resource","doc":"Ι represent a resource.\n\nDo not create with `%Anoma.Resource{}` directly, instead use\n`%{Anoma.Resource.new | ...}` for random nonce and seed.","ref":"Anoma.Resource.html"},{"type":"function","title":"Anoma.Resource.commitment/1","doc":"A commitment to the given resource.","ref":"Anoma.Resource.html#commitment/1"},{"type":"function","title":"Anoma.Resource.commits_to/2","doc":"Whether a commitment commits to a given resource.","ref":"Anoma.Resource.html#commits_to/2"},{"type":"function","title":"Anoma.Resource.commits_to_any/2","doc":"","ref":"Anoma.Resource.html#commits_to_any/2"},{"type":"function","title":"Anoma.Resource.delta/1","doc":"The delta of the given resource (kind and quantity).","ref":"Anoma.Resource.html#delta/1"},{"type":"function","title":"Anoma.Resource.from_noun/1","doc":"","ref":"Anoma.Resource.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.kind/1","doc":"The kind of the given resource (labelled logic).","ref":"Anoma.Resource.html#kind/1"},{"type":"function","title":"Anoma.Resource.new/0","doc":"New blank resource. Randomized nonce and seed.","ref":"Anoma.Resource.html#new/0"},{"type":"function","title":"Anoma.Resource.new_with_npk/1","doc":"Helper to pass in the npk for initializing a valid but meaningless\nresource.","ref":"Anoma.Resource.html#new_with_npk/1"},{"type":"function","title":"Anoma.Resource.nullifier/2","doc":"The nullifier of the given resource.\n(It's up to the caller to use the right secret.)","ref":"Anoma.Resource.html#nullifier/2"},{"type":"function","title":"Anoma.Resource.nullifies/2","doc":"Whether a nullifier nullifies a given resource.","ref":"Anoma.Resource.html#nullifies/2"},{"type":"function","title":"Anoma.Resource.nullifies_any/2","doc":"","ref":"Anoma.Resource.html#nullifies_any/2"},{"type":"function","title":"Anoma.Resource.to_noun/1","doc":"The resource as a noun.","ref":"Anoma.Resource.html#to_noun/1"},{"type":"function","title":"Anoma.Resource.transparent_committed_resource/1","doc":"","ref":"Anoma.Resource.html#transparent_committed_resource/1"},{"type":"function","title":"Anoma.Resource.transparent_run_resource_logic/2","doc":"","ref":"Anoma.Resource.html#transparent_run_resource_logic/2"},{"type":"type","title":"Anoma.Resource.t/0","doc":"","ref":"Anoma.Resource.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Delta","doc":"","ref":"Anoma.Resource.Delta.html"},{"type":"function","title":"Anoma.Resource.Delta.add/2","doc":"","ref":"Anoma.Resource.Delta.html#add/2"},{"type":"function","title":"Anoma.Resource.Delta.from_noun/1","doc":"","ref":"Anoma.Resource.Delta.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.Delta.negate/1","doc":"","ref":"Anoma.Resource.Delta.html#negate/1"},{"type":"function","title":"Anoma.Resource.Delta.sub/2","doc":"","ref":"Anoma.Resource.Delta.html#sub/2"},{"type":"function","title":"Anoma.Resource.Delta.to_noun/1","doc":"","ref":"Anoma.Resource.Delta.html#to_noun/1"},{"type":"type","title":"Anoma.Resource.Delta.t/0","doc":"","ref":"Anoma.Resource.Delta.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Proof","doc":"","ref":"Anoma.Resource.Proof.html"},{"type":"type","title":"Anoma.Resource.Proof.t/0","doc":"","ref":"Anoma.Resource.Proof.html#t:t/0"},{"type":"module","title":"Anoma.Resource.ProofRecord","doc":"","ref":"Anoma.Resource.ProofRecord.html"},{"type":"function","title":"Anoma.Resource.ProofRecord.from_noun/1","doc":"","ref":"Anoma.Resource.ProofRecord.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.ProofRecord.prove/1","doc":"","ref":"Anoma.Resource.ProofRecord.html#prove/1"},{"type":"function","title":"Anoma.Resource.ProofRecord.to_noun/1","doc":"","ref":"Anoma.Resource.ProofRecord.html#to_noun/1"},{"type":"type","title":"Anoma.Resource.ProofRecord.t/0","doc":"","ref":"Anoma.Resource.ProofRecord.html#t:t/0"},{"type":"module","title":"Anoma.Resource.Transaction","doc":"I represent a resource machine transaction","ref":"Anoma.Resource.Transaction.html"},{"type":"function","title":"Anoma.Resource.Transaction.compose/2","doc":"","ref":"Anoma.Resource.Transaction.html#compose/2"},{"type":"function","title":"Anoma.Resource.Transaction.from_noun/1","doc":"","ref":"Anoma.Resource.Transaction.html#from_noun/1"},{"type":"function","title":"Anoma.Resource.Transaction.partition_resources/3","doc":"","ref":"Anoma.Resource.Transaction.html#partition_resources/3"},{"type":"function","title":"Anoma.Resource.Transaction.to_noun/1","doc":"","ref":"Anoma.Resource.Transaction.html#to_noun/1"},{"type":"function","title":"Anoma.Resource.Transaction.verify/1","doc":"","ref":"Anoma.Resource.Transaction.html#verify/1"},{"type":"type","title":"Anoma.Resource.Transaction.t/0","doc":"","ref":"Anoma.Resource.Transaction.html#t:t/0"},{"type":"module","title":"Nock","doc":"Nock, a universal function on nouns.","ref":"Nock.html"},{"type":"function","title":"Nock.cons/2","doc":"","ref":"Nock.html#cons/2"},{"type":"function","title":"Nock.decrement_arm/0","doc":"","ref":"Nock.html#decrement_arm/0"},{"type":"function","title":"Nock.decrement_core/0","doc":"","ref":"Nock.html#decrement_core/0"},{"type":"function","title":"Nock.get_jet/1","doc":"","ref":"Nock.html#get_jet/1"},{"type":"function","title":"Nock.logics_core/0","doc":"","ref":"Nock.html#logics_core/0"},{"type":"function","title":"Nock.naive_nock/2","doc":"","ref":"Nock.html#naive_nock/2"},{"type":"function","title":"Nock.naive_nock/3","doc":"","ref":"Nock.html#naive_nock/3"},{"type":"function","title":"Nock.nock/2","doc":"","ref":"Nock.html#nock/2"},{"type":"function","title":"Nock.nock/3","doc":"","ref":"Nock.html#nock/3"},{"type":"function","title":"Nock.nock_0/1","doc":"","ref":"Nock.html#nock_0/1"},{"type":"function","title":"Nock.nock_1/1","doc":"","ref":"Nock.html#nock_1/1"},{"type":"function","title":"Nock.nock_2/2","doc":"","ref":"Nock.html#nock_2/2"},{"type":"function","title":"Nock.nock_3/1","doc":"","ref":"Nock.html#nock_3/1"},{"type":"function","title":"Nock.nock_4/1","doc":"","ref":"Nock.html#nock_4/1"},{"type":"function","title":"Nock.nock_5/2","doc":"","ref":"Nock.html#nock_5/2"},{"type":"function","title":"Nock.nock_6/3","doc":"","ref":"Nock.html#nock_6/3"},{"type":"function","title":"Nock.nock_7/2","doc":"","ref":"Nock.html#nock_7/2"},{"type":"function","title":"Nock.nock_8/2","doc":"","ref":"Nock.html#nock_8/2"},{"type":"function","title":"Nock.nock_9/2","doc":"","ref":"Nock.html#nock_9/2"},{"type":"function","title":"Nock.nock_10/3","doc":"","ref":"Nock.html#nock_10/3"},{"type":"function","title":"Nock.nock_11/2","doc":"","ref":"Nock.html#nock_11/2"},{"type":"function","title":"Nock.nock_11/3","doc":"","ref":"Nock.html#nock_11/3"},{"type":"function","title":"Nock.put_jet/2","doc":"","ref":"Nock.html#put_jet/2"},{"type":"function","title":"Nock.read_with_id/2","doc":"","ref":"Nock.html#read_with_id/2"},{"type":"function","title":"Nock.rm_core/0","doc":"","ref":"Nock.html#rm_core/0"},{"type":"function","title":"Nock.stdlib_core/0","doc":"","ref":"Nock.html#stdlib_core/0"},{"type":"type","title":"Nock.jettedness/0","doc":"","ref":"Nock.html#t:jettedness/0"},{"type":"type","title":"Nock.t/0","doc":"I contain environmental information on how Nock shall be evaluated.\n\nFor example Ι contain information on jettedness to\ndetermine if we should be using jets or not","ref":"Nock.html#t:t/0"},{"type":"module","title":"Nock.Cli","doc":"","ref":"Nock.Cli.html"},{"type":"function","title":"Nock.Cli.argument_option/0","doc":"","ref":"Nock.Cli.html#argument_option/0"},{"type":"function","title":"Nock.Cli.main/1","doc":"","ref":"Nock.Cli.html#main/1"},{"type":"module","title":"Nock.Jets","doc":"Jets for the Nock interpreter, taking a gate core. Not fully general.","ref":"Nock.Jets.html"},{"type":"function","title":"Nock.Jets.add/1","doc":"","ref":"Nock.Jets.html#add/1"},{"type":"function","title":"Nock.Jets.dec/1","doc":"","ref":"Nock.Jets.html#dec/1"},{"type":"function","title":"Nock.Jets.div/1","doc":"","ref":"Nock.Jets.html#div/1"},{"type":"function","title":"Nock.Jets.gte/1","doc":"","ref":"Nock.Jets.html#gte/1"},{"type":"function","title":"Nock.Jets.gth/1","doc":"","ref":"Nock.Jets.html#gth/1"},{"type":"function","title":"Nock.Jets.lte/1","doc":"","ref":"Nock.Jets.html#lte/1"},{"type":"function","title":"Nock.Jets.lth/1","doc":"","ref":"Nock.Jets.html#lth/1"},{"type":"function","title":"Nock.Jets.mod/1","doc":"","ref":"Nock.Jets.html#mod/1"},{"type":"function","title":"Nock.Jets.mul/1","doc":"","ref":"Nock.Jets.html#mul/1"},{"type":"function","title":"Nock.Jets.sample/1","doc":"","ref":"Nock.Jets.html#sample/1"},{"type":"function","title":"Nock.Jets.sub/1","doc":"","ref":"Nock.Jets.html#sub/1"},{"type":"module","title":"Noun","doc":"The noun data structure.\n\nRepresented as Elixir cons cells, which might get annoying.","ref":"Noun.html"},{"type":"function","title":"Noun.atom_binary_to_integer/1","doc":"","ref":"Noun.html#atom_binary_to_integer/1"},{"type":"function","title":"Noun.atom_integer_to_binary/1","doc":"","ref":"Noun.html#atom_integer_to_binary/1"},{"type":"function","title":"Noun.atom_integer_to_binary/2","doc":"","ref":"Noun.html#atom_integer_to_binary/2"},{"type":"function","title":"Noun.axis/2","doc":"","ref":"Noun.html#axis/2"},{"type":"function","title":"Noun.condensed_print/1","doc":"","ref":"Noun.html#condensed_print/1"},{"type":"function","title":"Noun.equal/2","doc":"","ref":"Noun.html#equal/2"},{"type":"macro","title":"Noun.is_noun_atom/1","doc":"","ref":"Noun.html#is_noun_atom/1"},{"type":"macro","title":"Noun.is_noun_cell/1","doc":"","ref":"Noun.html#is_noun_cell/1"},{"type":"function","title":"Noun.list_erlang_to_nock/1","doc":"","ref":"Noun.html#list_erlang_to_nock/1"},{"type":"function","title":"Noun.list_nock_to_erlang/1","doc":"","ref":"Noun.html#list_nock_to_erlang/1"},{"type":"function","title":"Noun.mug/1","doc":"","ref":"Noun.html#mug/1"},{"type":"function","title":"Noun.normalize_noun_atom/1","doc":"","ref":"Noun.html#normalize_noun_atom/1"},{"type":"function","title":"Noun.pad_trailing/2","doc":"","ref":"Noun.html#pad_trailing/2"},{"type":"function","title":"Noun.replace/3","doc":"","ref":"Noun.html#replace/3"},{"type":"type","title":"Noun.noun_atom/0","doc":"","ref":"Noun.html#t:noun_atom/0"},{"type":"type","title":"Noun.noun_cell/0","doc":"","ref":"Noun.html#t:noun_cell/0"},{"type":"type","title":"Noun.t/0","doc":"","ref":"Noun.html#t:t/0"},{"type":"module","title":"Noun.Format","doc":"Parsing and printing of nouns.","ref":"Noun.Format.html"},{"type":"function","title":"Noun.Format.parse/1","doc":"","ref":"Noun.Format.html#parse/1"},{"type":"function","title":"Noun.Format.parse_always/1","doc":"","ref":"Noun.Format.html#parse_always/1"},{"type":"function","title":"Noun.Format.parse_cell/1","doc":"","ref":"Noun.Format.html#parse_cell/1"},{"type":"function","title":"Noun.Format.parse_inner/1","doc":"","ref":"Noun.Format.html#parse_inner/1"},{"type":"function","title":"Noun.Format.parse_tail/1","doc":"","ref":"Noun.Format.html#parse_tail/1"},{"type":"function","title":"Noun.Format.print/1","doc":"","ref":"Noun.Format.html#print/1"},{"type":"function","title":"Noun.Format.print_tail/1","doc":"","ref":"Noun.Format.html#print_tail/1"},{"type":"module","title":"Anoma.Node","doc":"I act as a registry for Anoma Nodes\n\nThere are two ways to launch a Node. Either with minimal\narguments or having the full specification for all the\nengines, including their external ID's.\n\nAll inputs should come in format of a list of atom-value\n2-tuples, `{:settings, map()}` specifying the info on\nall relevant engines and storages possibly including their\ntables presented in a dumped format, `{:name, atom()}`\nspecifying the name of the node, and `{:new_storage, bool()}`\nspecifying whether the table names, if supplied, need to be\nset-up without any deletions.\n\nFor more info on format check `start_min/1`","ref":"Anoma.Node.html"},{"type":"module","title":"Minimal Arguments - Anoma.Node","doc":"- `name` - name for this process\n  - `snapshot_path` : [`atom()` | 0]\n    - A snapshot location for the service (used in the worker)\n  - `storage` : `Anoma.Storage.t()` - The Storage tables to use\n  - `block_storage` - a location to store the blocks produced\n\n#","ref":"Anoma.Node.html#module-minimal-arguments"},{"type":"module","title":"Created Tables - Anoma.Node","doc":"- `storage.qualified`\n  - `storage.order`\n  - `block_storage`","ref":"Anoma.Node.html#module-created-tables"},{"type":"function","title":"Anoma.Node.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.html#child_spec/1"},{"type":"function","title":"Anoma.Node.init/1","doc":"","ref":"Anoma.Node.html#init/1"},{"type":"function","title":"Anoma.Node.start_link/1","doc":"I assume I am fed a list with atom-value 2-tuples\n:new_storage, :name, :settings. If :new_storage has\nvalue true, I need a snapshot_path: key in the\nsettings.\n\nI ensure that the storages are deleted and created.\nAfterwards, if the storage is truly new, I put the snapshot\nin the ordering. Otherwise, I simply repopulate the tables\nfrom a supplied list by the settings.\nCheck Anoma.Dump for format descriptions.","ref":"Anoma.Node.html#start_link/1"},{"type":"function","title":"Anoma.Node.start_min/1","doc":"Given minimal arguments, I create appropriate setup for the\n`:settings` argument for Node initialization.","ref":"Anoma.Node.html#start_min/1"},{"type":"function","title":"Anoma.Node.state/1","doc":"","ref":"Anoma.Node.html#state/1"},{"type":"type","title":"Anoma.Node.t/0","doc":"","ref":"Anoma.Node.html#t:t/0"},{"type":"module","title":"Anoma.Node.Mempool","doc":"","ref":"Anoma.Node.Mempool.html"},{"type":"function","title":"Anoma.Node.Mempool.choose_and_execute_ordering/2","doc":"","ref":"Anoma.Node.Mempool.html#choose_and_execute_ordering/2"},{"type":"function","title":"Anoma.Node.Mempool.execute/1","doc":"","ref":"Anoma.Node.Mempool.html#execute/1"},{"type":"function","title":"Anoma.Node.Mempool.handle_call/3","doc":"","ref":"Anoma.Node.Mempool.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Mempool.handle_cast/3","doc":"","ref":"Anoma.Node.Mempool.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Mempool.handle_execute/1","doc":"","ref":"Anoma.Node.Mempool.html#handle_execute/1"},{"type":"function","title":"Anoma.Node.Mempool.handle_tx/2","doc":"","ref":"Anoma.Node.Mempool.html#handle_tx/2"},{"type":"function","title":"Anoma.Node.Mempool.hard_reset/1","doc":"","ref":"Anoma.Node.Mempool.html#hard_reset/1"},{"type":"function","title":"Anoma.Node.Mempool.init/1","doc":"","ref":"Anoma.Node.Mempool.html#init/1"},{"type":"function","title":"Anoma.Node.Mempool.kill_transactions/1","doc":"","ref":"Anoma.Node.Mempool.html#kill_transactions/1"},{"type":"function","title":"Anoma.Node.Mempool.order/2","doc":"","ref":"Anoma.Node.Mempool.html#order/2"},{"type":"function","title":"Anoma.Node.Mempool.order_format/2","doc":"","ref":"Anoma.Node.Mempool.html#order_format/2"},{"type":"function","title":"Anoma.Node.Mempool.pending_txs/1","doc":"","ref":"Anoma.Node.Mempool.html#pending_txs/1"},{"type":"function","title":"Anoma.Node.Mempool.persistent_transaction/1","doc":"","ref":"Anoma.Node.Mempool.html#persistent_transaction/1"},{"type":"function","title":"Anoma.Node.Mempool.produce_block/2","doc":"","ref":"Anoma.Node.Mempool.html#produce_block/2"},{"type":"function","title":"Anoma.Node.Mempool.random_id/0","doc":"","ref":"Anoma.Node.Mempool.html#random_id/0"},{"type":"function","title":"Anoma.Node.Mempool.reset_blocks/1","doc":"","ref":"Anoma.Node.Mempool.html#reset_blocks/1"},{"type":"function","title":"Anoma.Node.Mempool.reset_state/1","doc":"","ref":"Anoma.Node.Mempool.html#reset_state/1"},{"type":"function","title":"Anoma.Node.Mempool.save_block/2","doc":"","ref":"Anoma.Node.Mempool.html#save_block/2"},{"type":"function","title":"Anoma.Node.Mempool.soft_reset/1","doc":"","ref":"Anoma.Node.Mempool.html#soft_reset/1"},{"type":"function","title":"Anoma.Node.Mempool.state/1","doc":"","ref":"Anoma.Node.Mempool.html#state/1"},{"type":"function","title":"Anoma.Node.Mempool.tx/2","doc":"","ref":"Anoma.Node.Mempool.html#tx/2"},{"type":"type","title":"Anoma.Node.Mempool.t/0","doc":"","ref":"Anoma.Node.Mempool.html#t:t/0"},{"type":"type","title":"Anoma.Node.Mempool.transactions/0","doc":"","ref":"Anoma.Node.Mempool.html#t:transactions/0"},{"type":"module","title":"Anoma.Node.Executor","doc":"I Manage the Pub Sub behavior\n\nIf new intents come in, I send it to all my subscribers.\n\nFurther I have the job of spawning Executor tasks when new\ntransactions come in\n\nCurrently I only communicate:\n\n- When tasks are completed\n\n#","ref":"Anoma.Node.Executor.html"},{"type":"module","title":"API - Anoma.Node.Executor","doc":"My public facing API is\n\n- `new_transaction/3`\n- `new_transaction/4`\n- `fire_new_transaction/3`\n- `fire_new_transaction/4`\n- `snapshot/1`\n- `state/1`\n- `subscribe/2`","ref":"Anoma.Node.Executor.html#module-api"},{"type":"function","title":"Anoma.Node.Executor.fire_new_transaction/3","doc":"Acts like `new_transaction/3`, but the caller does not care about\nthe response. Instead the response is handled by the pool.\n\nThe user gets back a process so it may keep track of sending\nmessages to this task or terminating the task","ref":"Anoma.Node.Executor.html#fire_new_transaction/3"},{"type":"function","title":"Anoma.Node.Executor.fire_new_transaction/4","doc":"","ref":"Anoma.Node.Executor.html#fire_new_transaction/4"},{"type":"function","title":"Anoma.Node.Executor.handle_call/3","doc":"","ref":"Anoma.Node.Executor.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Executor.handle_cast/2","doc":"","ref":"Anoma.Node.Executor.html#handle_cast/2"},{"type":"function","title":"Anoma.Node.Executor.handle_info/2","doc":"","ref":"Anoma.Node.Executor.html#handle_info/2"},{"type":"function","title":"Anoma.Node.Executor.init/1","doc":"","ref":"Anoma.Node.Executor.html#init/1"},{"type":"function","title":"Anoma.Node.Executor.kill_transactions/2","doc":"","ref":"Anoma.Node.Executor.html#kill_transactions/2"},{"type":"function","title":"Anoma.Node.Executor.new_transaction/3","doc":"Spawns a new transaction, the returned task's owner is the caller.\n\n#","ref":"Anoma.Node.Executor.html#new_transaction/3"},{"type":"function","title":"Inputs - Anoma.Node.Executor.new_transaction/3","doc":"- `executor` - the genserver to send the message to\n  - `order` - the unique ID of the transaction\n  - `gate` - a Nock function that we will spawn a task for\n\n#","ref":"Anoma.Node.Executor.html#new_transaction/3-inputs"},{"type":"function","title":"Output - Anoma.Node.Executor.new_transaction/3","doc":"- a task that the caller owns\n\n#","ref":"Anoma.Node.Executor.html#new_transaction/3-output"},{"type":"function","title":"Example - Anoma.Node.Executor.new_transaction/3","doc":"we assume a running Worker, see `executor_test.exs` for a full\n  example\n\n    > id = System.unique_integer([:positive])\n    1931\n    > zero = [[1, 777 | 0], 0, Nock.stdlib_core()]\n    > task = Executor.new_transaction(executor, id, {:kv, zero})\n    %Task{\n      mfa: {Anoma.Node.Executor.Worker, :run, 3},\n      owner: #PID<0.264.0>,\n      pid: #PID<0.753.0>,\n      ref: #Reference<0.0.33795.904691850.4087414796.24378>\n    }","ref":"Anoma.Node.Executor.html#new_transaction/3-example"},{"type":"function","title":"Anoma.Node.Executor.new_transaction/4","doc":"","ref":"Anoma.Node.Executor.html#new_transaction/4"},{"type":"function","title":"Anoma.Node.Executor.snapshot/1","doc":"Returns the snapshot path, the Nock code is using\n\n#","ref":"Anoma.Node.Executor.html#snapshot/1"},{"type":"function","title":"Example - Anoma.Node.Executor.snapshot/1","doc":"iex> alias Anoma.Node.{Executor, Router}\n  iex> {:ok, router} = Router.start\n  iex> snap = %Nock{snapshot_path: [:a | 0], ordering: nil}\n  iex> args = {snap, Router.new_topic(router), nil}\n  iex> {:ok, addr} = Router.start_engine(router, Executor, args)\n  iex> Executor.snapshot(addr)\n  :a","ref":"Anoma.Node.Executor.html#snapshot/1-example"},{"type":"function","title":"Anoma.Node.Executor.state/1","doc":"Returns the current state of the executor","ref":"Anoma.Node.Executor.html#state/1"},{"type":"type","title":"Anoma.Node.Executor.t/0","doc":"","ref":"Anoma.Node.Executor.html#t:t/0"},{"type":"module","title":"Anoma.Node.Executor.Worker","doc":"I am a Nock worker, supporting scry.","ref":"Anoma.Node.Executor.Worker.html"},{"type":"function","title":"Anoma.Node.Executor.Worker.rm_nullifier_check/2","doc":"","ref":"Anoma.Node.Executor.Worker.html#rm_nullifier_check/2"},{"type":"function","title":"Anoma.Node.Executor.Worker.run/3","doc":"","ref":"Anoma.Node.Executor.Worker.html#run/3"},{"type":"function","title":"Anoma.Node.Executor.Worker.snapshot/2","doc":"","ref":"Anoma.Node.Executor.Worker.html#snapshot/2"},{"type":"function","title":"Anoma.Node.Executor.Worker.wait_for_ready/2","doc":"","ref":"Anoma.Node.Executor.Worker.html#wait_for_ready/2"},{"type":"module","title":"Anoma.Identity.Backend","doc":"I determine which backend to use in order to generate or connect an identity.","ref":"Anoma.Identity.Backend.html"},{"type":"type","title":"Anoma.Identity.Backend.t/0","doc":"","ref":"Anoma.Identity.Backend.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Backend.Local","doc":"I represent generating the keys on some sort of local storage that\nis connected to Anoma","ref":"Anoma.Identity.Backend.Local.html"},{"type":"type","title":"Anoma.Identity.Backend.Local.t/0","doc":"","ref":"Anoma.Identity.Backend.Local.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Backend.Memory","doc":"I keep the identity in memory. I may or may not persisting across\nreboots. This depends if the table is set to disc_only copies, or\nmemory_copies","ref":"Anoma.Identity.Backend.Memory.html"},{"type":"type","title":"Anoma.Identity.Backend.Memory.t/0","doc":"We determine the information needed to properly store a memory copy.\n\n#","ref":"Anoma.Identity.Backend.Memory.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Identity.Backend.Memory.t/0","doc":"- `symmetric` - this is a symmetric encryption/decryption key\n    known by the user and the system. This key will be used to\n    encrypt the public and private key, and along with the\n    `External.t/1` can index into table\n\n - `table` - this is the local table in which where in memory this\n   will be stored","ref":"Anoma.Identity.Backend.Memory.html#t:t/0-fields"},{"type":"module","title":"Anoma.Identity.Backend.Remote","doc":"I denote that the identity creation should be routed to some\n`t:Anoma.Crypto.Id.Extern.t/0`","ref":"Anoma.Identity.Backend.Remote.html"},{"type":"type","title":"Anoma.Identity.Backend.Remote.t/0","doc":"","ref":"Anoma.Identity.Backend.Remote.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Capabilities","doc":"I specify which capabilities to request when generating a new\nidentity or connecting an existing one.","ref":"Anoma.Identity.Capabilities.html"},{"type":"function","title":"Anoma.Identity.Capabilities.commit/0","doc":"","ref":"Anoma.Identity.Capabilities.html#commit/0"},{"type":"function","title":"Anoma.Identity.Capabilities.commit_and_decrypt/0","doc":"","ref":"Anoma.Identity.Capabilities.html#commit_and_decrypt/0"},{"type":"function","title":"Anoma.Identity.Capabilities.decrypt/0","doc":"","ref":"Anoma.Identity.Capabilities.html#decrypt/0"},{"type":"type","title":"Anoma.Identity.Capabilities.t/0","doc":"","ref":"Anoma.Identity.Capabilities.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Encapsulated","doc":"I contain the information necessary for engines like:\n  - `Anoma.Node.Identity.Decryption`\n  - `Anoma.Node.Identity.Commitment`\n\nto operate.\n\nTo speak plainly, I contain the secret information necessary to\ndecrypt and encrypt messages","ref":"Anoma.Identity.Encapsulated.html"},{"type":"type","title":"Anoma.Identity.Encapsulated.t/0","doc":"","ref":"Anoma.Identity.Encapsulated.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Encryption","doc":"I am responsible for encrypting messages to external identities. It\nautomatically uses \"reads for\" relationship information from the\nReads For Engine along with caller preference information in order\nto choose which identity to encrypt to.","ref":"Anoma.Identity.Encryption.html"},{"type":"function","title":"Anoma.Identity.Encryption.seal/3","doc":"","ref":"Anoma.Identity.Encryption.html#seal/3"},{"type":"module","title":"Anoma.Identity.Evidence","doc":"","ref":"Anoma.Identity.Evidence.html"},{"type":"type","title":"Anoma.Identity.Evidence.name/0","doc":"","ref":"Anoma.Identity.Evidence.html#t:name/0"},{"type":"type","title":"Anoma.Identity.Evidence.t/1","doc":"","ref":"Anoma.Identity.Evidence.html#t:t/1"},{"type":"module","title":"Anoma.Identity.Manager","doc":"I am responsible for generating, connecting, and deleting identities.\n\nI abstracts a uniform interface over identities created with\ndifferent \"backends\", including, for example:\n\n  - internal identities stored in local memory\n  - internal identities stored in a hardware device, e.g. Ledger\n  - internal identities stored in a browser extension\n  - internal identities stored in another machine accessible over the network\n\nWhen an identity is generated or connected, the I do not return the\ninternal identity directly, but rather returns handles to the\ncorresponding commitment and decryption engine instances, which can\nbe used to generate commitments by and decrypt data encrypted to,\nrespectively, the internal identity (which is still kept in whatever\nbackend is in use).","ref":"Anoma.Identity.Manager.html"},{"type":"function","title":"Anoma.Identity.Manager.connect/3","doc":"","ref":"Anoma.Identity.Manager.html#connect/3"},{"type":"function","title":"Anoma.Identity.Manager.delete/2","doc":"I delete the given key.\n\nNote that depending on the backend the following could happen:\n\n1. If there is an active Decryption and Commitment engine and the\n   backend is a memory backend, then the keys can still be used for\n   singing and decryption. However once these engines die there is\n   not a way to get them back after deletion.\n2. If there is an active Decryption and Commitment engine and the\n   backend is external, then they can't be used anymore as the\n   actual keys are gone from the external device.\n3. One can no longer connect to the key given it does not exist in\n   the system anymore","ref":"Anoma.Identity.Manager.html#delete/2"},{"type":"function","title":"Anoma.Identity.Manager.generate/3","doc":"","ref":"Anoma.Identity.Manager.html#generate/3"},{"type":"type","title":"Anoma.Identity.Manager.instance/0","doc":"","ref":"Anoma.Identity.Manager.html#t:instance/0"},{"type":"type","title":"Anoma.Identity.Manager.resp/1","doc":"","ref":"Anoma.Identity.Manager.html#t:resp/1"},{"type":"module","title":"Anoma.Identity.Name","doc":"","ref":"Anoma.Identity.Name.html"},{"type":"function","title":"Anoma.Identity.Name.add/3","doc":"Adds the given key to the given namespace. The signer who owns the\nnamespace must have signed.","ref":"Anoma.Identity.Name.html#add/3"},{"type":"function","title":"Anoma.Identity.Name.all_identities/2","doc":"","ref":"Anoma.Identity.Name.html#all_identities/2"},{"type":"function","title":"Anoma.Identity.Name.name_space/0","doc":"","ref":"Anoma.Identity.Name.html#name_space/0"},{"type":"function","title":"Anoma.Identity.Name.reserve_namespace/4","doc":"","ref":"Anoma.Identity.Name.html#reserve_namespace/4"},{"type":"type","title":"Anoma.Identity.Name.t/0","doc":"","ref":"Anoma.Identity.Name.html#t:t/0"},{"type":"module","title":"Anoma.Identity.Parameters","doc":"I specify what parameters to use when generating a new identity.","ref":"Anoma.Identity.Parameters.html"},{"type":"type","title":"Anoma.Identity.Parameters.t/0","doc":"","ref":"Anoma.Identity.Parameters.html#t:t/0"},{"type":"module","title":"Anoma.Identity.SignsFor","doc":"","ref":"Anoma.Identity.SignsFor.html"},{"type":"function","title":"Anoma.Identity.SignsFor.known/2","doc":"","ref":"Anoma.Identity.SignsFor.html#known/2"},{"type":"function","title":"Anoma.Identity.SignsFor.name_space/0","doc":"","ref":"Anoma.Identity.SignsFor.html#name_space/0"},{"type":"function","title":"Anoma.Identity.SignsFor.sign_for/2","doc":"","ref":"Anoma.Identity.SignsFor.html#sign_for/2"},{"type":"function","title":"Anoma.Identity.SignsFor.signs_for?/3","doc":"","ref":"Anoma.Identity.SignsFor.html#signs_for?/3"},{"type":"module","title":"Anoma.Identity.Verification","doc":"I am responsible for verifying commitments made by external\nidentities. I automatically uses \"signs for\" relationship\ninformation from the Anoma.Identity.SignsFor along with caller preference\ninformation in order to choose how to verify a commitment.","ref":"Anoma.Identity.Verification.html"},{"type":"function","title":"Anoma.Identity.Verification.verify_combined/3","doc":"","ref":"Anoma.Identity.Verification.html#verify_combined/3"},{"type":"function","title":"Anoma.Identity.Verification.verify_request/4","doc":"","ref":"Anoma.Identity.Verification.html#verify_request/4"},{"type":"module","title":"Anoma.Node.Identity.Commitment","doc":"","ref":"Anoma.Node.Identity.Commitment.html"},{"type":"function","title":"Anoma.Node.Identity.Commitment.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Identity.Commitment.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Identity.Commitment.commit/2","doc":"","ref":"Anoma.Node.Identity.Commitment.html#commit/2"},{"type":"function","title":"Anoma.Node.Identity.Commitment.commit_combined/2","doc":"","ref":"Anoma.Node.Identity.Commitment.html#commit_combined/2"},{"type":"function","title":"Anoma.Node.Identity.Commitment.init/1","doc":"","ref":"Anoma.Node.Identity.Commitment.html#init/1"},{"type":"function","title":"Anoma.Node.Identity.Commitment.start_link/1","doc":"","ref":"Anoma.Node.Identity.Commitment.html#start_link/1"},{"type":"module","title":"Anoma.Node.Identity.Decryption","doc":"","ref":"Anoma.Node.Identity.Decryption.html"},{"type":"function","title":"Anoma.Node.Identity.Decryption.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.Identity.Decryption.html#child_spec/1"},{"type":"function","title":"Anoma.Node.Identity.Decryption.decrypt/2","doc":"","ref":"Anoma.Node.Identity.Decryption.html#decrypt/2"},{"type":"function","title":"Anoma.Node.Identity.Decryption.init/1","doc":"","ref":"Anoma.Node.Identity.Decryption.html#init/1"},{"type":"function","title":"Anoma.Node.Identity.Decryption.start_link/1","doc":"","ref":"Anoma.Node.Identity.Decryption.html#start_link/1"},{"type":"module","title":"Anoma.Node.IntentPool","doc":"","ref":"Anoma.Node.IntentPool.html"},{"type":"function","title":"Anoma.Node.IntentPool.child_spec/1","doc":"Returns a specification to start this module under a supervisor.\n\nSee `Supervisor`.","ref":"Anoma.Node.IntentPool.html#child_spec/1"},{"type":"function","title":"Anoma.Node.IntentPool.handle_cast/3","doc":"","ref":"Anoma.Node.IntentPool.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.IntentPool.init/1","doc":"","ref":"Anoma.Node.IntentPool.html#init/1"},{"type":"function","title":"Anoma.Node.IntentPool.intents/1","doc":"","ref":"Anoma.Node.IntentPool.html#intents/1"},{"type":"function","title":"Anoma.Node.IntentPool.new_intent/2","doc":"","ref":"Anoma.Node.IntentPool.html#new_intent/2"},{"type":"function","title":"Anoma.Node.IntentPool.remove_intent/2","doc":"","ref":"Anoma.Node.IntentPool.html#remove_intent/2"},{"type":"type","title":"Anoma.Node.IntentPool.intents/0","doc":"","ref":"Anoma.Node.IntentPool.html#t:intents/0"},{"type":"type","title":"Anoma.Node.IntentPool.t/0","doc":"","ref":"Anoma.Node.IntentPool.html#t:t/0"},{"type":"module","title":"Anoma.Node.Storage.Ordering","doc":"I am a simple mnesia-backed key-value store in an anoma node.\n\nCurrently we do not have a way of propagating what keys users want\nto store, thus we take the following approach to deterministic state\nreading:\n\n  1. We keep a next_order, which represents the next_order a\n     transaction will have. From here the scry reads specifically\n     [next_order, :key_space | 0] to get a map of the current keys\n     saved for this node.\n\n  2. We keep a hash_to_order to cache the id => order mapping","ref":"Anoma.Node.Storage.Ordering.html"},{"type":"function","title":"Anoma.Node.Storage.Ordering.caller_blocking_read_id/2","doc":"Translate from ids to true order\n\n#","ref":"Anoma.Node.Storage.Ordering.html#caller_blocking_read_id/2"},{"type":"function","title":"Parameters - Anoma.Node.Storage.Ordering.caller_blocking_read_id/2","doc":"- `ordering` - the ordering process\n\n  - `[id | subkey]` -\n\n   the process identification for consistent reads, and a subkey for\n   the storage key. This is akin to the `Storage.qualified_key` in\n   `Storage.blocking_read/2`\n\n#","ref":"Anoma.Node.Storage.Ordering.html#caller_blocking_read_id/2-parameters"},{"type":"function","title":"Returns - Anoma.Node.Storage.Ordering.caller_blocking_read_id/2","doc":"returns the given key at a specific value","ref":"Anoma.Node.Storage.Ordering.html#caller_blocking_read_id/2-returns"},{"type":"function","title":"Anoma.Node.Storage.Ordering.get_storage/1","doc":"","ref":"Anoma.Node.Storage.Ordering.html#get_storage/1"},{"type":"function","title":"Anoma.Node.Storage.Ordering.handle_call/3","doc":"","ref":"Anoma.Node.Storage.Ordering.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Storage.Ordering.handle_cast/3","doc":"","ref":"Anoma.Node.Storage.Ordering.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Storage.Ordering.handle_new_order/2","doc":"","ref":"Anoma.Node.Storage.Ordering.html#handle_new_order/2"},{"type":"function","title":"Anoma.Node.Storage.Ordering.hard_reset/2","doc":"","ref":"Anoma.Node.Storage.Ordering.html#hard_reset/2"},{"type":"function","title":"Anoma.Node.Storage.Ordering.init/1","doc":"","ref":"Anoma.Node.Storage.Ordering.html#init/1"},{"type":"function","title":"Anoma.Node.Storage.Ordering.new_order/2","doc":"","ref":"Anoma.Node.Storage.Ordering.html#new_order/2"},{"type":"function","title":"Anoma.Node.Storage.Ordering.next_order/1","doc":"","ref":"Anoma.Node.Storage.Ordering.html#next_order/1"},{"type":"function","title":"Anoma.Node.Storage.Ordering.reset/1","doc":"","ref":"Anoma.Node.Storage.Ordering.html#reset/1"},{"type":"function","title":"Anoma.Node.Storage.Ordering.state/1","doc":"","ref":"Anoma.Node.Storage.Ordering.html#state/1"},{"type":"function","title":"Anoma.Node.Storage.Ordering.true_order/2","doc":"","ref":"Anoma.Node.Storage.Ordering.html#true_order/2"},{"type":"type","title":"Anoma.Node.Storage.Ordering.key/0","doc":"","ref":"Anoma.Node.Storage.Ordering.html#t:key/0"},{"type":"type","title":"Anoma.Node.Storage.Ordering.ordered_transactions/0","doc":"","ref":"Anoma.Node.Storage.Ordering.html#t:ordered_transactions/0"},{"type":"type","title":"Anoma.Node.Storage.Ordering.t/0","doc":"","ref":"Anoma.Node.Storage.Ordering.html#t:t/0"},{"type":"module","title":"Anoma.Order","doc":"I am the Order module, I am the format responsible for making sure\nthat the given process is told that it can be read or executed at\nthe given index","ref":"Anoma.Order.html"},{"type":"function","title":"Anoma.Order.id/1","doc":"","ref":"Anoma.Order.html#id/1"},{"type":"function","title":"Anoma.Order.index/1","doc":"","ref":"Anoma.Order.html#index/1"},{"type":"function","title":"Anoma.Order.new/3","doc":"","ref":"Anoma.Order.html#new/3"},{"type":"function","title":"Anoma.Order.pid/1","doc":"","ref":"Anoma.Order.html#pid/1"},{"type":"type","title":"Anoma.Order.t/0","doc":"I am the Order type. I have information regarding a correct order\nand having a proper host to ping to notify when it can do a certain\ntask.\n\n#","ref":"Anoma.Order.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Order.t/0","doc":"- `index` - the ordering index to execute at\n  - `id` - the identification key path of the requested key\n  - `pid` - the process identifier to message","ref":"Anoma.Order.html#t:t/0-fields"},{"type":"module","title":"Anoma.Storage","doc":"I am the Anoma Storage engine, I consist of two parts:\n   1. An ordering map which tells of the latest order in the\n      qualification map\n   2. A qualification map which maps from a qualified key to the stored\n      value","ref":"Anoma.Storage.html"},{"type":"module","title":"Types - Anoma.Storage","doc":"A good way to view this is that for the `t()`, the fields for what\n  is stored in mnesia, are simply the order_* and qualified_* values\n\n  type `t Anoma.Storage` to find them all.\n\n  Please also type `t Anoma.Storage.t()` to find out more about the\n  central type","ref":"Anoma.Storage.html#module-types"},{"type":"module","title":"API - Anoma.Storage","doc":"The important functions for this API are\n   - `setup/1`\n   - `ensure_new/1`\n   - `get/2`\n   - `get/3`\n   - `put/3`\n   - `put/4`\n   - `blocking_read/2`\n   - `blocking_read/3`\n\nFor Querying keyspace the following functions are useful\n  - `get_keyspace/2`\n\nIf one wants to query the tables by hand then there are manual\nfunctions, but beware, this is an unintended way of using the API\n   - `query_key_space/2`\n   - `read_order/2`\n   - `read_order_tx/2`\n   - `read_at_order/3`\n   - `read_at_order_tx/3`\n   - `write_at_order/4`\n   - `write_at_order_tx/4`\n\n\nPlease see my testing module `AnomaTest.Storage` to learn more on\nhow to use me\n\n#","ref":"Anoma.Storage.html#module-api"},{"type":"module","title":"Snapshots - Anoma.Storage","doc":"One can snapshot the keys provided in the code by running the following\n\n  - `snapshot_order/1`\n  - `put_snapshot/2`\n  - `in_snapshot/2`\n  - `get_at_snapshot/2`","ref":"Anoma.Storage.html#module-snapshots"},{"type":"function","title":"Anoma.Storage.blocking_read/2","doc":"","ref":"Anoma.Storage.html#blocking_read/2"},{"type":"function","title":"Anoma.Storage.calculate_order/1","doc":"","ref":"Anoma.Storage.html#calculate_order/1"},{"type":"function","title":"Anoma.Storage.check_if_any_absent/1","doc":"","ref":"Anoma.Storage.html#check_if_any_absent/1"},{"type":"function","title":"Anoma.Storage.cm_tree_spec/0","doc":"","ref":"Anoma.Storage.html#cm_tree_spec/0"},{"type":"function","title":"Anoma.Storage.ensure_new/1","doc":"","ref":"Anoma.Storage.html#ensure_new/1"},{"type":"function","title":"Anoma.Storage.get/2","doc":"","ref":"Anoma.Storage.html#get/2"},{"type":"function","title":"Anoma.Storage.get_at_snapshot/2","doc":"","ref":"Anoma.Storage.html#get_at_snapshot/2"},{"type":"function","title":"Anoma.Storage.get_keyspace/2","doc":"","ref":"Anoma.Storage.html#get_keyspace/2"},{"type":"function","title":"Anoma.Storage.in_snapshot/2","doc":"","ref":"Anoma.Storage.html#in_snapshot/2"},{"type":"function","title":"Anoma.Storage.put/3","doc":"","ref":"Anoma.Storage.html#put/3"},{"type":"function","title":"Anoma.Storage.put_snapshot/2","doc":"","ref":"Anoma.Storage.html#put_snapshot/2"},{"type":"function","title":"Anoma.Storage.read_at_order/3","doc":"","ref":"Anoma.Storage.html#read_at_order/3"},{"type":"function","title":"Anoma.Storage.read_at_order_tx/3","doc":"","ref":"Anoma.Storage.html#read_at_order_tx/3"},{"type":"function","title":"Anoma.Storage.read_keyspace_order/2","doc":"Reads the given keyspace to obtain the latest orders for the keys","ref":"Anoma.Storage.html#read_keyspace_order/2"},{"type":"function","title":"Anoma.Storage.read_order/2","doc":"","ref":"Anoma.Storage.html#read_order/2"},{"type":"function","title":"Anoma.Storage.read_order_tx/2","doc":"","ref":"Anoma.Storage.html#read_order_tx/2"},{"type":"function","title":"Anoma.Storage.remove/1","doc":"","ref":"Anoma.Storage.html#remove/1"},{"type":"function","title":"Anoma.Storage.setup/1","doc":"I setup storage with the given tables: `t()`.\n\nI will try to setup all values of storage, even if the first one\nfails due to already being setup, we will try the others.","ref":"Anoma.Storage.html#setup/1"},{"type":"function","title":"Anoma.Storage.snapshot_order/1","doc":"","ref":"Anoma.Storage.html#snapshot_order/1"},{"type":"function","title":"Anoma.Storage.write_at_order/4","doc":"","ref":"Anoma.Storage.html#write_at_order/4"},{"type":"function","title":"Anoma.Storage.write_at_order_tx/4","doc":"","ref":"Anoma.Storage.html#write_at_order_tx/4"},{"type":"type","title":"Anoma.Storage.order_key/0","doc":"The key we wish to store, also used for order lookup","ref":"Anoma.Storage.html#t:order_key/0"},{"type":"type","title":"Anoma.Storage.order_value/0","doc":"","ref":"Anoma.Storage.html#t:order_value/0"},{"type":"type","title":"Anoma.Storage.qualified_key/0","doc":"[non_neg_integer(), Noun.t() | non_neg_integer()]","ref":"Anoma.Storage.html#t:qualified_key/0"},{"type":"type","title":"Anoma.Storage.qualified_value/0","doc":"","ref":"Anoma.Storage.html#t:qualified_value/0"},{"type":"type","title":"Anoma.Storage.result/1","doc":"","ref":"Anoma.Storage.html#t:result/1"},{"type":"type","title":"Anoma.Storage.snapshot/0","doc":"","ref":"Anoma.Storage.html#t:snapshot/0"},{"type":"type","title":"Anoma.Storage.t/0","doc":"I represent the qualified and ordered data of storage","ref":"Anoma.Storage.html#t:t/0"},{"type":"type","title":"Fields - Anoma.Storage.t/0","doc":"- `:qualified` - The key value value map into storage\n  - `:order` - A mapping from keys to the properly qualified keys","ref":"Anoma.Storage.html#t:t/0-fields"},{"type":"module","title":"Anoma.Crypto.Encrypt","doc":"","ref":"Anoma.Crypto.Encrypt.html"},{"type":"function","title":"Anoma.Crypto.Encrypt.new_keypair/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Encrypt.seal/2","doc":"I seal the given message for the publicly known recipient.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Encrypt.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Encrypt.unseal/3","doc":"","ref":"Anoma.Crypto.Encrypt.html#unseal/3"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.box_secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:box_secret/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.public/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Encrypt.secret/0","doc":"","ref":"Anoma.Crypto.Encrypt.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Id","doc":"I represent the Identity","ref":"Anoma.Crypto.Id.html"},{"type":"function","title":"Anoma.Crypto.Id.decode/1","doc":"","ref":"Anoma.Crypto.Id.html#decode/1"},{"type":"function","title":"Anoma.Crypto.Id.encode/2","doc":"Serializes it for Mnesia","ref":"Anoma.Crypto.Id.html#encode/2"},{"type":"function","title":"Anoma.Crypto.Id.initalize/2","doc":"I initialize the table to be used locally.\n\n#","ref":"Anoma.Crypto.Id.html#initalize/2"},{"type":"function","title":"Parameters - Anoma.Crypto.Id.initalize/2","doc":"- `table` - the table name to store the data under\n   - `kind` - the kind of table this should be","ref":"Anoma.Crypto.Id.html#initalize/2-parameters"},{"type":"function","title":"Anoma.Crypto.Id.new_keypair/0","doc":"","ref":"Anoma.Crypto.Id.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Id.salt_keys/2","doc":"I salt the given keys for storage further storage. Or for storage\nlookup\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for salting for storage\n- `Extern.t\u0000` is useful for looking up keys for storage\n- `Intern.t\u0000` is useful in case one wants to see the salted key","ref":"Anoma.Crypto.Id.html#salt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.seal/2","doc":"","ref":"Anoma.Crypto.Id.html#seal/2"},{"type":"function","title":"Anoma.Crypto.Id.unsalt_keys/2","doc":"I unsalt the given keys for use after looking up from storage\n\nI can be used on `t\u0000`, `Intern.t\u0000` or `Extern.t\u0000`.\n\n- `t\u0000` is useful for unsalting from Storage\n- `Extern.t\u0000` is useful for external keys which are salted\n- `Intern.t\u0000` is useful in case when one wants to unsalt their private keys","ref":"Anoma.Crypto.Id.html#unsalt_keys/2"},{"type":"function","title":"Anoma.Crypto.Id.verify/2","doc":"","ref":"Anoma.Crypto.Id.html#verify/2"},{"type":"type","title":"Anoma.Crypto.Id.identities/0","doc":"","ref":"Anoma.Crypto.Id.html#t:identities/0"},{"type":"type","title":"Anoma.Crypto.Id.t/0","doc":"","ref":"Anoma.Crypto.Id.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Extern","doc":"","ref":"Anoma.Crypto.Id.Extern.html"},{"type":"type","title":"Anoma.Crypto.Id.Extern.t/0","doc":"","ref":"Anoma.Crypto.Id.Extern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Id.Intern","doc":"","ref":"Anoma.Crypto.Id.Intern.html"},{"type":"type","title":"Anoma.Crypto.Id.Intern.t/0","doc":"","ref":"Anoma.Crypto.Id.Intern.html#t:t/0"},{"type":"module","title":"Anoma.Crypto.Randomness","doc":"I am an implementation of the Local Randomness Engine","ref":"Anoma.Crypto.Randomness.html"},{"type":"function","title":"Anoma.Crypto.Randomness.get_random/1","doc":"Given a non-negative integer N, I provide a random bit of size N","ref":"Anoma.Crypto.Randomness.html#get_random/1"},{"type":"module","title":"Anoma.Crypto.Sign","doc":"","ref":"Anoma.Crypto.Sign.html"},{"type":"function","title":"Anoma.Crypto.Sign.new_keypair/0","doc":"","ref":"Anoma.Crypto.Sign.html#new_keypair/0"},{"type":"function","title":"Anoma.Crypto.Sign.sign/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign/2"},{"type":"function","title":"Anoma.Crypto.Sign.sign_detatched/2","doc":"","ref":"Anoma.Crypto.Sign.html#sign_detatched/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify/2","doc":"","ref":"Anoma.Crypto.Sign.html#verify/2"},{"type":"function","title":"Anoma.Crypto.Sign.verify_detatched/3","doc":"","ref":"Anoma.Crypto.Sign.html#verify_detatched/3"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_public/0"},{"type":"type","title":"Anoma.Crypto.Sign.ed25519_secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:ed25519_secret/0"},{"type":"type","title":"Anoma.Crypto.Sign.public/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:public/0"},{"type":"type","title":"Anoma.Crypto.Sign.secret/0","doc":"","ref":"Anoma.Crypto.Sign.html#t:secret/0"},{"type":"module","title":"Anoma.Crypto.Symmetric","doc":"","ref":"Anoma.Crypto.Symmetric.html"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.decrypt_raw/2","doc":"","ref":"Anoma.Crypto.Symmetric.html#decrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt/2","doc":"I encrypt data given any known schema and a message.\n\nThe message will be turned into binary via :erlang.term_to_binary,\nso please do not turn it to binary before hand.","ref":"Anoma.Crypto.Symmetric.html#encrypt/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.encrypt_raw/2","doc":"I encrypt data given any known schema and a message.\n\nI am raw in that I do not serialize the data, Only use me if you\nknow what you are doing.","ref":"Anoma.Crypto.Symmetric.html#encrypt_raw/2"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_key/0"},{"type":"function","title":"Anoma.Crypto.Symmetric.random_xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#random_xchacha_nonce/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.t/0","doc":"I represent the symmetric types available to the system","ref":"Anoma.Crypto.Symmetric.html#t:t/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_key/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_key/0"},{"type":"type","title":"Anoma.Crypto.Symmetric.xchacha_nonce/0","doc":"","ref":"Anoma.Crypto.Symmetric.html#t:xchacha_nonce/0"},{"type":"module","title":"Anoma.Node.Solver","doc":"I am a strawman intent solver for testing purposes.","ref":"Anoma.Node.Solver.html"},{"type":"function","title":"Anoma.Node.Solver.get_solved/1","doc":"","ref":"Anoma.Node.Solver.html#get_solved/1"},{"type":"function","title":"Anoma.Node.Solver.handle_call/3","doc":"","ref":"Anoma.Node.Solver.html#handle_call/3"},{"type":"function","title":"Anoma.Node.Solver.handle_cast/3","doc":"","ref":"Anoma.Node.Solver.html#handle_cast/3"},{"type":"function","title":"Anoma.Node.Solver.init/1","doc":"","ref":"Anoma.Node.Solver.html#init/1"},{"type":"function","title":"Anoma.Node.Solver.mempool_send/2","doc":"","ref":"Anoma.Node.Solver.html#mempool_send/2"},{"type":"function","title":"Anoma.Node.Solver.solve/1","doc":"","ref":"Anoma.Node.Solver.html#solve/1"},{"type":"type","title":"Anoma.Node.Solver.t/0","doc":"","ref":"Anoma.Node.Solver.html#t:t/0"},{"type":"module","title":"CommitmentTree","doc":"A simple commitment tree.\n\nCurrently stores all commitments forever, and stores the full tree in memory,\npending future more sophisticated retention policies.  Does not yet store any\nanchors itself for the same reason--this is a complex policy level decision.\n\nHas a fixed depth.\n\nFiats that empty subtrees have a hash of 0 for simplicity.","ref":"CommitmentTree.html"},{"type":"function","title":"CommitmentTree.add/2","doc":"Adds commitments to the commitment tree, and returns the new tree and the anchor.\nTODO handle the tree's filling up","ref":"CommitmentTree.html#add/2"},{"type":"function","title":"CommitmentTree.init_storage/1","doc":"","ref":"CommitmentTree.html#init_storage/1"},{"type":"function","title":"CommitmentTree.new/2","doc":"Creates a new `CommitmentTree` struct.","ref":"CommitmentTree.html#new/2"},{"type":"function","title":"CommitmentTree.prove/2","doc":"","ref":"CommitmentTree.html#prove/2"},{"type":"type","title":"CommitmentTree.t/0","doc":"","ref":"CommitmentTree.html#t:t/0"},{"type":"module","title":"CommitmentTree.Node","doc":"","ref":"CommitmentTree.Node.html"},{"type":"function","title":"CommitmentTree.Node.new/2","doc":"Creates a new internal node.\nChildren is a tuple of size spec.splay, each element of which is either a binary or another node.","ref":"CommitmentTree.Node.html#new/2"},{"type":"function","title":"CommitmentTree.Node.new_empty/1","doc":"Creates a new internal node, all children of which are empty.","ref":"CommitmentTree.Node.html#new_empty/1"},{"type":"function","title":"CommitmentTree.Node.prove/3","doc":"Produces a proof for leaf #cursor of node, taking the form of a nested tuple,\nas described in proof.ex","ref":"CommitmentTree.Node.html#prove/3"},{"type":"type","title":"CommitmentTree.Node.t/0","doc":"","ref":"CommitmentTree.Node.html#t:t/0"},{"type":"module","title":"CommitmentTree.Proof","doc":"I represent a compact proof that a particular element is contained within the\ncommitment tree.","ref":"CommitmentTree.Proof.html"},{"type":"function","title":"CommitmentTree.Proof.new/2","doc":"","ref":"CommitmentTree.Proof.html#new/2"},{"type":"function","title":"CommitmentTree.Proof.verify/4","doc":"","ref":"CommitmentTree.Proof.html#verify/4"},{"type":"function","title":"CommitmentTree.Proof.verifyx/5","doc":"","ref":"CommitmentTree.Proof.html#verifyx/5"},{"type":"type","title":"CommitmentTree.Proof.t/0","doc":"","ref":"CommitmentTree.Proof.html#t:t/0"},{"type":"module","title":"CommitmentTree.Spec","doc":"A specification for a commitment tree.","ref":"CommitmentTree.Spec.html"},{"type":"function","title":"CommitmentTree.Spec.new/4","doc":"","ref":"CommitmentTree.Spec.html#new/4"},{"type":"type","title":"CommitmentTree.Spec.t/0","doc":"","ref":"CommitmentTree.Spec.html#t:t/0"},{"type":"module","title":"Anoma.Mnesia","doc":"I help with various queries around *Mnesia*.\n\n#","ref":"Anoma.Mnesia.html"},{"type":"module","title":"Usage - Anoma.Mnesia","doc":"i> Anoma.Mnesia.init()\n\n#","ref":"Anoma.Mnesia.html#module-usage"},{"type":"module","title":"Initialization - Anoma.Mnesia","doc":"I can help with initializing *Mnesia*. calling `init/0` should setup\nthe project to be compatible with\n\nNote that the Erlang Node I reside in can only have one Mnesia\ndatabase open at a time.\n\n#","ref":"Anoma.Mnesia.html#module-initialization"},{"type":"module","title":"Querying - Anoma.Mnesia","doc":"I have the following functions that can help query data\n\n  - `dirt_dump/1`","ref":"Anoma.Mnesia.html#module-querying"},{"type":"function","title":"Anoma.Mnesia.attach/0","doc":"","ref":"Anoma.Mnesia.html#attach/0"},{"type":"function","title":"Anoma.Mnesia.dirty_dump/1","doc":"I help dump all data in a given table\n\n#","ref":"Anoma.Mnesia.html#dirty_dump/1"},{"type":"function","title":"Example - Anoma.Mnesia.dirty_dump/1","doc":"iex(15)> :mnesia.create_table(:test, [attributes: [:id, :name, :job]])\n     {:atomic, :ok}\n     iex(16)> :mnesia.dirty_write({:test, 1, \"G'kar\", \"Ambassador\"})\n     :ok\n     iex(17)> Anoma.Mnesia.dirty_dump(:test)\n     [[{:test, 1, \"G'kar\", \"Ambassador\"}]]","ref":"Anoma.Mnesia.html#dirty_dump/1-example"},{"type":"function","title":"Anoma.Mnesia.dump/1","doc":"I help dump all data in a given table in a non-dirty way.\n\nSee `dirty_dump/1`","ref":"Anoma.Mnesia.html#dump/1"},{"type":"function","title":"Anoma.Mnesia.init/0","doc":"","ref":"Anoma.Mnesia.html#init/0"},{"type":"module","title":"Anoma.Node.Utility","doc":"I have utility functions that are common amongst all Node\n\n#","ref":"Anoma.Node.Utility.html"},{"type":"module","title":"Argument Constructors - Anoma.Node.Utility","doc":"I contain common arguments for constructing genserver arguments:\n\n  - `name/1`\n\n\n#","ref":"Anoma.Node.Utility.html#module-argument-constructors"},{"type":"module","title":"Tracing Utilities - Anoma.Node.Utility","doc":"- `message_label/1`\n\n#","ref":"Anoma.Node.Utility.html#module-tracing-utilities"},{"type":"module","title":"Communicators - Anoma.Node.Utility","doc":"I also contain functions that make creating Communicators easier\n\n  - `name/2`\n  - `com_name/1`\n  - `broadcast/2`","ref":"Anoma.Node.Utility.html#module-communicators"},{"type":"function","title":"Anoma.Node.Utility.append_name/2","doc":"","ref":"Anoma.Node.Utility.html#append_name/2"},{"type":"function","title":"Anoma.Node.Utility.broadcast/2","doc":"I broadcast a given term to all subscribers\n\n#","ref":"Anoma.Node.Utility.html#broadcast/2"},{"type":"function","title":"Parameters - Anoma.Node.Utility.broadcast/2","doc":"- `subs` - the subscribers, we accept any enumerable term\n  - `term` - the given term we wish to broadcast","ref":"Anoma.Node.Utility.html#broadcast/2-parameters"},{"type":"function","title":"Anoma.Node.Utility.com_name/1","doc":"I create a communicator name from a given atom\n\n#","ref":"Anoma.Node.Utility.html#com_name/1"},{"type":"function","title":"Parameters - Anoma.Node.Utility.com_name/1","doc":"- `name` (atom) - the original name","ref":"Anoma.Node.Utility.html#com_name/1-parameters"},{"type":"function","title":"Returns - Anoma.Node.Utility.com_name/1","doc":"The name with a communicator tag appended to it","ref":"Anoma.Node.Utility.html#com_name/1-returns"},{"type":"function","title":"Examples - Anoma.Node.Utility.com_name/1","doc":"iex> Anoma.Node.Utility.com_name(:joe)\n    :joe_com","ref":"Anoma.Node.Utility.html#com_name/1-examples"},{"type":"function","title":"Anoma.Node.Utility.message_label/1","doc":"Helps labeling for `Kino.Process.seq_trace/2`, for the Router abstraction","ref":"Anoma.Node.Utility.html#message_label/1"},{"type":"function","title":"Anoma.Node.Utility.name/1","doc":"Grabs the name out of the given `Keyword` argument list, and returns\na keyword list only with name\n\n#","ref":"Anoma.Node.Utility.html#name/1"},{"type":"function","title":"Parameters - Anoma.Node.Utility.name/1","doc":"- `arg` - the keyword argument list","ref":"Anoma.Node.Utility.html#name/1-parameters"},{"type":"function","title":"Anoma.Node.Utility.name/2","doc":"Grabs the name out of the given `Keyword` argument list, and applies\na given function over the resulting name, returning an altered name.\n\n#","ref":"Anoma.Node.Utility.html#name/2"},{"type":"function","title":"Parameters - Anoma.Node.Utility.name/2","doc":"- `arg` - the keyword argument list\n  - `name_alteration` - a function that alters the given name","ref":"Anoma.Node.Utility.html#name/2-parameters"},{"type":"module","title":"TestHelper.Nock","doc":"I am a testing module that has some common definitions for nock\nfunctions.","ref":"TestHelper.Nock.html"},{"type":"function","title":"TestHelper.Nock.factorial/0","doc":"","ref":"TestHelper.Nock.html#factorial/0"},{"type":"function","title":"TestHelper.Nock.increment_counter_val/1","doc":"","ref":"TestHelper.Nock.html#increment_counter_val/1"},{"type":"function","title":"TestHelper.Nock.using_dec_core/0","doc":"","ref":"TestHelper.Nock.html#using_dec_core/0"},{"type":"function","title":"TestHelper.Nock.zero_counter/1","doc":"","ref":"TestHelper.Nock.html#zero_counter/1"},{"type":"extras","title":"Anoma","doc":"# Anoma\n\nThis is an implementation of the Anoma protocol, whose specs can be\nfound [here](https://specs.anoma.net/alpha).","ref":"readme.html"},{"type":"extras","title":"Following Development - Anoma","doc":"Work is merged into `base` on a bi-weekly (once every two weeks)\nschedule.\n\nDevelopment can be followed in multiple ways:\n\n1. [Issues are put into the project overview](https://github.com/orgs/anoma/projects/19)\n   - This is a good way to see what work is assigned and the various\n     views into how goals are being met\n2. [Promise Graph from the project overview](https://specs.anoma.net/projects/anoma-19.html)\n   - This is the same information as `1.` but using our own promise\n     graph tooling. This is kept up to date hourly.\n3. [What's Cooking on Anoma](https://github.com/orgs/anoma/projects/20 \"A good view on how topics are progressing throughout a cycle\")\n4. [Issues](https://github.com/anoma/anoma/issues) and [pull requests](https://github.com/anoma/anoma/pulls)\n   - This is good for viewing new issues and work coming in, but the\n     other views are typically a better way to view this","ref":"readme.html#following-development"},{"type":"extras","title":"Dependencies - Anoma","doc":"To have a working Anoma Node the following dependencies are required:\n\n1. `cmake`\n2. `Erlang`\n3. `Elixir`\n4. `zig`\n\n#","ref":"readme.html#dependencies"},{"type":"extras","title":"OSX - Anoma","doc":"```sh\nbrew install elixir\nbrew install zig\n```\n\n#","ref":"readme.html#osx"},{"type":"extras","title":"Linux - Anoma","doc":"All the dependencies can be grabbed from your distro's package manager.","ref":"readme.html#linux"},{"type":"extras","title":"Installation - Anoma","doc":"To install the dependencies as well as Anoma run:\n\n```bash\nmix deps.get\nmix compile\n```\n\nTo start an Anoma instance run one of these:\n\n```bash\niex -S mix # starts an interactive shell\nmix run --no-halt # starts a non-interactive shell\n```\n\nSee the Contributing section for how to get the best use of the\ninteractive shell.","ref":"readme.html#installation"},{"type":"extras","title":"Contributing - Anoma","doc":"Please read the [contributor's guide](./documentation/CONTRIBUTING.livemd) for in\ndepth details about the codebase.\n\n#","ref":"readme.html#contributing"},{"type":"extras","title":"Git - Anoma","doc":"This codebase follows a git style similar to\n[git](https://git-scm.com/) or\n[linux](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git).\n\nNew code should be based on `base`, and no attempt to keep it up to\nsync with `main` should be had. When one's topic is ready, just submit\na PR on github and a maintainer will handle any merge conflicts.\n\nThere are bi-weekly releases, so do not be afraid if a maintainer says\nthe PR is merged but it's still open, this just means that it's merged\ninto `next` or `main` and will be included in the next scheduled\nrelease.\n\nFor more information on a smooth git experience check out the [git\nsection in contributor's guide](./documentation/contributing/git.livemd)\n\nHappy hacking, and don't be afraid to submit patches.","ref":"readme.html#git"},{"type":"extras","title":"Index","doc":"# Index\n\n```elixir\nMix.install([\n  {:kino, \"~> 0.12.0\"}\n])\n```","ref":"index.html"},{"type":"extras","title":"Index - Index","doc":"1. [Contributing](./CONTRIBUTING.livemd)\n   1. [Git](./contributing/git.livemd)\n   2. [Hoon](./contributing/hoon.livemd)\n   3. [Iex](./contributing/iex.livemd)\n   4. [Observer](./contributing/observer.livemd)\n   5. [Testing](./contributing/testing.livemd)\n      1. [Running Tests](./contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n   6. [Understanding](./contributing/understanding.livemd)\n2. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n3. [Index](./index.livemd)\n4. [Index_docs](./index_docs.livemd)\n5. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n6. [Vm_interface](./vm_interface.livemd)","ref":"index.html#index"},{"type":"extras","title":"TOC - Index","doc":"This notebook organizes a set of lessons to help you get started with Anoma!\n\nThis book uses livebook, it is best viewed from within it! However most sections can be viewed fine in github or your text editor.","ref":"index.html#toc"},{"type":"extras","title":"Anoma VM interface","doc":"# Anoma VM interface\n\nThe Anoma VM proceeds by executing user code, written in Nock, in several\nexecution contexts. This document details the various available execution\ncontexts, and the interface the VM uses to interoperate with Nock code.","ref":"vm_interface.html"},{"type":"extras","title":"The Executor context - Anoma VM interface","doc":"The Executor context proceeds according to one of several modes:\n\n- `kv` mode: updates keys in a simple key-value store, and\n- `rm` mode: assembles resource machine transactions to be passed to the\n  resource machine context.\n\nAn additional mode is planned for the shielded resource machine, when\nintegrated; and `kv` mode is an early prototype of what will evolve into\nthe content-addressed blob storage facility.\n\n`kv` and `rm` modes share the same execution interface: they expect a Nock\n`gate`. A `gate` is a function-like object with the following form:\n\n```\n[code [sample context]]\n```\n\n`code` is a Nock formula intended to be run with the gate as subject, while\n`sample` is a placeholder for arguments to the gate. `context` contains any\nadditional code or data referenced; this includes at least the standard\nlibrary, but may be larger than it.\n\nIn both `kv` and `rm` modes, the submitted transaction is a gate, and the\nargument placed in the sample is its opaque order ID. The output expected\nis the following tuple:\n\n```\n[[read-keyspaces write-keyspaces] second-gate]\n```\n\nIn `kv` mode, `read-keyspaces` and `write-keyspaces` are subspaces of the\nkey-value store which the transaction plans to read or write, respectively.\nThe VM may use this information to place locks or otherwise prepare for\ntransaction execution. It is an error to read outside the declared\n`read-keyspaces` or write outside the declared `write-keyspaces`\n\nIn `rm` mode, `read-keyspaces` and `write-keyspaces` are always the entire\n`rm` keyspace. Every `rm` transaction updates the commitment and nullifier\ntrees.\n\nThe scry operation is illegal in the execution of the first gate, because\nthe transaction has not declared its read locks yet.\n\nThe second gate may perform the scry operation. It is more properly termed\na `trap` as it takes no arguments. However, its scries are restricted to\nthe `read-keyspaces` returned along with it.\n\nThe scry operation blocks until its read lock is released by the VM. It may\nfail, causing the whole transaction to fail, if it reads an invalid or\ndisallowed key.\n\nThe second gate's output is a list of key-value pairs to update in `kv`\nmode, and a resource machine transaction in `rm` mode.","ref":"vm_interface.html#the-executor-context"},{"type":"extras","title":"The Resource Machine context - Anoma VM interface","doc":"When the VM's resource machine implementation processes a resource\ntransaction, this includes the execution of resource logics in each\nresource. Shielded resource transactions will proceed similarly, but\nwithin the shielded VM rather than the Nock VM.\n\nA resource logic is also a gate, and the arguments it takes are the tuple\n\n```\n[self resource-transaction]\n```\n\nwhere `self` is a copy of the entire resource running the logic, and\n`resource-transaction` is the Nock serialization of the entire resource\ntransaction (which includes all resources, in the transparent resource\nmachine).\n\nIts output is a simple boolean: `0` for success, `1` for failure.","ref":"vm_interface.html#the-resource-machine-context"},{"type":"extras","title":"Gas metering - Anoma VM interface","doc":"All Nock execution is metered simply: starting with a meter value of 0,\nincrementing by 1 for each recursion back into simple Nock evaluation,\nand incrementing by a defined per-jet constant for each jet invoked.","ref":"vm_interface.html#gas-metering"},{"type":"extras","title":"Index","doc":"# Index\n\n```elixir\nMix.install([\n  {:kino, \"~> 0.12.0\"}\n])\n```","ref":"index_docs.html"},{"type":"extras","title":"Index - Index","doc":"1. [Contributing](./CONTRIBUTING.livemd)\n   1. [Git](./contributing/git.livemd)\n   2. [Hoon](./contributing/hoon.livemd)\n   3. [Iex](./contributing/iex.livemd)\n   4. [Observer](./contributing/observer.livemd)\n   5. [Testing](./contributing/testing.livemd)\n      1. [Running Tests](./contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n   6. [Understanding](./contributing/understanding.livemd)\n2. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n3. [Index](./index.livemd)\n4. [Index_docs](./index_docs.livemd)\n5. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n6. [Vm_interface](./vm_interface.livemd)","ref":"index_docs.html#index"},{"type":"extras","title":"TOC - Index","doc":"This notebook organizes a set of lessons to help you get started with Anoma!\n\nThis book uses livebook, it is best viewed from within it! However most sections can be viewed fine in github or your text editor.","ref":"index_docs.html#toc"},{"type":"extras","title":"Contributing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Contributing","ref":"contributing.html"},{"type":"extras","title":"Index - Contributing","doc":"1. [Contributing](./CONTRIBUTING.livemd)\n   1. [Git](./contributing/git.livemd)\n   2. [Hoon](./contributing/hoon.livemd)\n   3. [Iex](./contributing/iex.livemd)\n   4. [Observer](./contributing/observer.livemd)\n   5. [Testing](./contributing/testing.livemd)\n      1. [Running Tests](./contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n   6. [Understanding](./contributing/understanding.livemd)\n2. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n3. [Index](./index.livemd)\n4. [Index_docs](./index_docs.livemd)\n5. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n6. [Vm_interface](./vm_interface.livemd)","ref":"contributing.html#index"},{"type":"extras","title":"Contributing - Contributing","doc":"Please view any concept in the index for any sections you may be interested in.\n\nPlease feel free to contribute to these docs and improve them!","ref":"contributing.html#contributing"},{"type":"extras","title":"Git","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Git","ref":"git.html"},{"type":"extras","title":"Index - Git","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"git.html#index"},{"type":"extras","title":"Git - Git","doc":"Git is a decent version control(VC) system, however there are ways to\nmake the VC process a lot smoother.\n\nThis document is best viewed from within liveview, as the charts do not render on github currently.","ref":"git.html#git"},{"type":"extras","title":"Terminology - Git","doc":"* `topic` - this is any branch that serves to fix some problem in the\n  codebase\n\n* `feature` - some new concept to the codebase. Many topics can serve\n  to fulfill one feature.\n\n* `release` - A release of the code. This is a git `tag` on `main`\n  that signifies a new version of the software. This typically bumps\n  base to the latest release as well\n\n* `base` - the base branch one should base work off of\n\n* `main` - sometimes called `master`, is the branch that prepares for\n  a release.\n\n* `next` - a branch that has a superset of features that will be\n  included in the next release\n\n* `maint` - a maintnance branch that will be updated if bugs are found\n\n* `integreation branch` - a topic that merges a bunch of other topics","ref":"git.html#terminology"},{"type":"extras","title":"Naming conventions - Git","doc":"Name your topic like `name/feature` to avoid clashing with other\npeople's topics.\n\nThere are some standard branches that do not follow this pattern but\nthose are described in the `Terminology` section of this document","ref":"git.html#naming-conventions"},{"type":"extras","title":"General Principles - Git","doc":"These are some general principles which should help maintainers easily\nintegrate your code, and have your work help out other devs on the\ncodebase.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#general-principles"},{"type":"extras","title":"Do not include unrelated changes into your commits - Git","doc":"* For example, if you see some unrelated bug in the same file as your\n  own, don't fix it in your general commit, make a new topic based on\n  when the bug was introduced and merge that into your topic if it\n  impacts your topic.\n\n* This makes reviewing much easier as the reviewer can read your\n  commit message and see changes only related to that included\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#do-not-include-unrelated-changes-into-your-commits"},{"type":"extras","title":"Make topics early and often! - Git","doc":"This allows your work to be incrementally integrated into a\nrelease. If you put all your work into one topic, bug fixes and all,\nthen the following will occur\n\n1. The changes will not be reviewed properly\n\n   * On big projects with tight deadlines, sometimes some feature\n     *X* is wanted. However if *X* is a single topic with a messy\n     history, the only options are either to scrap the feature or\n     accept it as is poor code in all.\n   * If this was properly split up parts of *X* could be merged\n     now, with the more controversial features being held up in\n     *next*, without having to sacrifice the quality of the\n     codebase.\n\n2. Other team members can not share similar work\n\n   * Often a lot of different tasks, may find the same\n     deficiencies in the codebase.\n\n   * For a real example, let's take the following commit and topic\n\n     ```example\n     802ab9e * anoma/mariari/nock-testing-file Move the helper functions\n     73bfd7d * v0.3.0\n      2 files changed, 44 insertions(+), 34 deletions(-)\n     lib/test_helper/nock.ex | 43 +++++++++++++++++++++++++++++++++++++++++++\n     test/nock_test.exs      | 35 +----------------------------------\n     ```\n\n     Here we find that we `mariari` moved some testing functions from\n     `test/` to `lib/`, as elixir tests don't share code in the best\n     way. This allows other files in `test/` to reuse the same\n     functions that were previously found in `test/nock_test.exs`.  In\n     fact there are multiple topics that ended up using this. Both the\n     executor topic and worker topic\n\n     * `8de0c7e anoma/mariari/worker`\n       * `1d6bc99 anoma/mariari/executor`\n\n     both needed this. Since the worker relies upon the executor,\n     they both don't merge in this topic separately, but if they\n     were separate they would want to share this change.\n\n* If these changes were orchestrated by different people, then\n  they would have made this change twice! Meaning that in the git\n  history the work has been done in different commits! This means\n  that when it comes time to merge in work, there will be a\n  conflict between these two. Rather than being able to reuse\n  other's work and save other devs time, this will come up when\n  reviewers read the code, with unrelated changes, or when the\n  maintainers try to merge things together and find annoying\n  conflicts\n\n1. Work can not be incrementally included\n2. Others might just do the work before you\n\n* If one is too slow on finishing their topic and making it one big\n  commit, then someone else might redo the same work and put it up\n  for review, but instead of them reusing your code, they wrote it\n  from scratch, wasting both your time and their time.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#make-topics-early-and-often"},{"type":"extras","title":"Base topics on base - Git","doc":"Basing code on `main` has the following errors:\n\n1. Code merged in main before a release may turn out to have issues\n2. Git merges and conflict resolutions lead to spurious base points\n3. Other topics can not reuse your code\n4. Useless temporal history is had\n\nBasing on someone's topic that you require and will merge in anyways\nis fine.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n#","ref":"git.html#base-topics-on-base"},{"type":"extras","title":"Code merged in main before a release may turn out to have issues - Git","doc":"Imagine main has the following history\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout base\nmerge Topic-Y id: \"52b44a6\"\n```\n\nand your code hapens to be base on 52b44a6, then the history will look something like:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'my-cool-feature'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch Topic-Y\ncommit id: \"4381bd3\"\ncheckout my-cool-feature\nmerge Topic-Y id: \"52b44a6: main merge feature-y\"\ncommit id: \"7dabf44\"\n```\n\nLater before a release, we find out that *Topic-Y* has issues, and any\ncode that is based on *Topic-Y* will have to sit this release\nout. Normally to check for this, the protocol is quite simple we just:\n\n1. Do not include any topics that are based on *Topic-Y* or merges\n   *Topic-Y* into the release\n2. Pull any topic based on *Topic-Y* from `main`\n\nbecomes muddied, as if one's topic was based on `main` after *Topic-Y*\nis in, then it's unclear if that topic is unaffected.\n\nThus *my-cool-feature* may be cut from the release, even if it was\nperfectly fine and did not rely on *Topic-Y*.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n#","ref":"git.html#code-merged-in-main-before-a-release-may-turn-out-to-have-issues"},{"type":"extras","title":"Git merges and conflict resolutions lead to spurious base points - Git","doc":"Further, if we have two topics *my-feature-x* and *my-feature-y* based\non `main`, then the history would look something like this\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'base'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d\" tag: \"v0.3.0\"\nbranch main\nbranch ray/mnesia-attach\ncommit id: \"97bef7\"\ncheckout main\nmerge ray/mnesia-attach id: \"13b3e4a\"\n\n\ncheckout base\nbranch proper-topic\ncommit id: \"8087564: add a new feature\"\n\ncheckout main\nbranch topic-x\ncommit id: \"bc4b2a1: new cool feature\"\n\ncheckout main\nmerge proper-topic id: \"2dd991a\"\n\ncheckout main\nbranch topic-y\ncommit id: \"546a8f9: add feature: conflicts X!\"\n\ncheckout main\nmerge topic-x id: \"90d91e7\"\nmerge topic-y id: \"0438922\"\n```\n\nIn a textual form this looks like:\n\n```\n0438922 *   main Merge branch 'topic-y'\n        |\\\n546a8f9 | * topic-y Added a feature that conflcits with X!\n90d91e7 * |   Merge branch 'topic-x'\n        |\\ \\\n        | |/\n        |/|\nbc4b2a1 | * topic-x Added a cool feature\n2dd991a * |   Merge branch 'proper-topic'\n        |\\ \\\n        | |/\n        |/|\n8087564 | * proper-topic Add a new feature\n13b3e4a * |   Merge branch 'ray/mnesia-attach'\n        |\\ \\\n        | |/\n        |/|\n97b6ef7 | * ray/mnesia-attach mnesia:\n        |/\n73bfd7d * v0.3.0 base\n\n```\n\nWhen *topic-x* and *topic-y* have a conflict, the shared base of their base is\n\n```bash\n4 taichi@Gensokyo:~/Documents/Work/Repo/anoma-all git:main: % git merge-base topic-x topic-y\n13b3e4a215ea6222a1b1092ad242d3fa31e7040b\n```\n\nwhich is `13b3e4a * | Merge branch 'ray/mnesia-attach'` and not\n`73bfd7d * v0.3.0 anoma/base`, meaning that when a conflict is shown\nin the merge `0438922`, then the diff from a 3 way diff will show the\nmnesia changes, potentially making it unclear to others way the\npotentially issues may be.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n#","ref":"git.html#git-merges-and-conflict-resolutions-lead-to-spurious-base-points"},{"type":"extras","title":"Other topics can not reuse your code - Git","doc":"It is a bad idea to base code on `main`, as `main` contains random\nmerged topics before a release. This makes it so other topics who wish\nto use yours also has to merge all the random topics on `main`.\n\nThis is easy to see with the following example:\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'simple-config'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n```\n\nHere we have a topic `major-changes` that makes all sorts of changes,\nand since we based our code off main, these are all included in\nsimple-config-change.\n\nHowever imagine we wish to overhaul the configuration a bit\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\ncommit id: \"f098de0: Basic config changes\"\n```\n\nNow if we wish to merge in `simple-config-change` we have\n\n```mermaid\n%%{init:\n{ 'logLevel': 'debug',\n  'theme': 'forest',\n  'gitGraph': {'showBranches': true,\n               'showCommitLabel':true,\n               'mainBranchName': 'configuration-upgrade'}} }%%\ngitGraph TB:\ncommit id: \"73bfd7d: base\" tag: \"v0.3.0\"\n\nbranch simple-config\ncheckout configuration-upgrade\nbranch major-changes\ncommit id: \"97bef7: structural changes\"\n\ncheckout configuration-upgrade\ncommit id: \"f098de0: Basic config changes\"\n\ncheckout simple-config\nmerge major-changes id: \"5b16844: merge into main\"\ncommit id: \"f098de0: general config\"\n\ncheckout configuration-upgrade\nmerge simple-config id: \"f6230df\"\n```\n\nBesides having a spurious main merged into our topic now, we are\nforced to deal with `major-changes` causing various conflicts with\nyour topic, making this merge untenable.\n\nMeaning that this code has to be recreated in `configuration-upgrade`\ninstead of reusing `simple-config-change`, fixing the problem in 2\nplaces, and having a conflict when it comes time for a release.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n#","ref":"git.html#other-topics-can-not-reuse-your-code"},{"type":"extras","title":"Useless temporal history is had - Git","doc":"As we can see in the previous examples, when we base off of `main`, we\nend up in a scenario, where the date in which someone is branching is\nbaked into the code. As maintainers we don't care about when the code\nwas made, just the fact that it was. Thus this is a bit of history\nthat simply adds noise\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#useless-temporal-history-is-had"},{"type":"extras","title":"Merge other people's topics into yours - Git","doc":"If you need some work that is already merged into `next` or `main`,\nsimply merge that topic into yours! Since the bases are well situated,\nyou will only deal with reasonable conflicts that you should have\ncontext for.\n\n<!-- livebook:{\"branch_parent_index\":4} -->","ref":"git.html#merge-other-people-s-topics-into-yours"},{"type":"extras","title":"Base bug fixes on the commit that introduced the bug - Git","doc":"Basing a bug fix on when the bug is introduced is superior than basing\nit on the latest release, as this means that it can be merged into any\n`maint` branches we may have.\n\nFor example:\n\n```\n73bfd7d * v0.3.0 Anoma 0.3.0\n...\n10f8636 * v0.2.0 Anoma 0.2.0\n...\n34fcd78 * v0.1.0 Release v0.1.0\n```\n\nif a bug was found in a topic between `v0.1.0` and `v0.2.0`, and we\nbased it on when the bug was found we can merge it on `v0.2.0` and\nhave `v0.2.1` release from there. And have a `v0.3.1` release as well.\n\n```\n2373834 *   v0.2.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n10f8636 * | v0.2.0 Anoma 0.2.0\n```\n\n```\n19c6f03 *   v0.3.1 Merge branch 'bug-fix' into HEAD\n        |\\\nda24431 | * bug-fix fix bug\n73bfd7d * | v0.3.0 Anoma 0.3.0\n```\n\nnotice how we can merge this in with no conflicts!","ref":"git.html#base-bug-fixes-on-the-commit-that-introduced-the-bug"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-1.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"hoon-1.html#index"},{"type":"extras","title":"Hoon - Hoon","doc":"Currently the quickest way to write resource logics is to have Hoon\nsetup and working. Checkout the [Hoon section for more information](../hoon.livemd)","ref":"hoon-1.html#hoon"},{"type":"extras","title":"IEx","doc":"# IEx","ref":"iex.html"},{"type":"extras","title":"Index - IEx","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"iex.html#index"},{"type":"extras","title":"Running multiple IEX's in the same Image/Environments - IEx","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\nMIX_ENV=test iex --sname b@localhost --cookie anoma -S mix\n# open a new terminal\nMIX_ENV=test iex --remsh b@localhost --sname c@localhost --cookie anoma -S mix\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis also allows you to connect from [livebook](https://livebook.dev)\nby using the above cookie `anoma` under the `runtime` config of\nlivebook.","ref":"iex.html#running-multiple-iex-s-in-the-same-image-environments"},{"type":"extras","title":"Observer","doc":"<!-- livebook:{\"file_entries\":[{\"name\":\"2024-01-08-172805_1016x497_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-173044_1845x1082_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174448_1283x720_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174522_1420x684_scrot.png\",\"type\":\"attachment\"},{\"name\":\"2024-01-08-174628_443x186_scrot.png\",\"type\":\"attachment\"},{\"name\":\"Application_view.jpg\",\"type\":\"attachment\"}],\"persist_outputs\":true} -->\n\n# Observer","ref":"observer.html"},{"type":"extras","title":"Index - Observer","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"observer.html#index"},{"type":"extras","title":"How To use Observer - Observer","doc":"It is sometimes useful to have multiple terminals/IEX's in the same\nrunning system, or perhaps to connect to a running deploy Anoma\nInstance. We can connect to other IEX instances in this way:","ref":"observer.html#how-to-use-observer"},{"type":"extras","title":"Viewing Anoma - Observer","doc":"One can view Anoma by going to the Applications view of the Observer pane and clicking on anoma\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/Application_view.jpg)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis view is quite nice because if we spawn a process, we can see it attach\n\n```elixir\nalias Anoma.Storage\nalias Anoma.Node.Storage.Communicator, as: Scom\nalias Anoma.Node.Executor.Communicator, as: Ccom\nalias Anoma.Node.Mempool.Communicator, as: Mcom\nimport TestHelper.Nock\n\nstorage = %Anoma.Storage{\n  qualified: Anoma.Qualified,\n  order: Anoma.Order\n}\n\nname = :anoma\nsnapshot_path = [:my_special_nock_snaphsot | 0]\nnode = Anoma.Node.com_names(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mcom.tx(node.mempool, zero).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.4479.0>\n```\n\nThen we can see this same process as a child to one of the pools\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-172805_1016x497_scrot.png)","ref":"observer.html#viewing-anoma"},{"type":"extras","title":"Looking at Mnesia Tables - Observer","doc":"One can go to the Table view, and click view to turn it from `ets` tables to `mnesia` tables.\n\nNow you should be able to see this:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174522_1420x684_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nIf we click on a table like the one highlighted we can see the values in the table\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174448_1283x720_scrot.png)\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nClick on the data inside of here gives us an inspector pane of the data\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n![](files/2024-01-08-174628_443x186_scrot.png)","ref":"observer.html#looking-at-mnesia-tables"},{"type":"extras","title":"Testing","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Testing","ref":"testing.html"},{"type":"extras","title":"Index - Testing","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"testing.html#index"},{"type":"extras","title":"Testing - Testing","doc":"Testing is important for the Anoma Project.\n\nThese series of documents cover how best to traverse tests throughout the project.","ref":"testing.html#testing"},{"type":"extras","title":"Running Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Running Tests","ref":"running-tests.html"},{"type":"extras","title":"Index - Running Tests","doc":"1. [Contributing](./../../CONTRIBUTING.livemd)\n   1. [Git](./../../contributing/git.livemd)\n   2. [Hoon](./../../contributing/hoon.livemd)\n   3. [Iex](./../../contributing/iex.livemd)\n   4. [Observer](./../../contributing/observer.livemd)\n   5. [Testing](./../../contributing/testing.livemd)\n      1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../../contributing/understanding.livemd)\n2. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n3. [Index](./../../index.livemd)\n4. [Index_docs](./../../index_docs.livemd)\n5. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n6. [Vm_interface](./../../vm_interface.livemd)","ref":"running-tests.html#index"},{"type":"extras","title":"Writing Tests","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Writing Tests","ref":"writing-tests.html"},{"type":"extras","title":"Index - Writing Tests","doc":"1. [Contributing](./../../CONTRIBUTING.livemd)\n   1. [Git](./../../contributing/git.livemd)\n   2. [Hoon](./../../contributing/hoon.livemd)\n   3. [Iex](./../../contributing/iex.livemd)\n   4. [Observer](./../../contributing/observer.livemd)\n   5. [Testing](./../../contributing/testing.livemd)\n      1. [Running Tests](./../../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../../contributing/understanding.livemd)\n2. [Hoon](./../../hoon.livemd)\n   1. [Calling](./../../hoon/calling.livemd)\n   2. [Dumping](./../../hoon/dumping.livemd)\n   3. [Setting Up](./../../hoon/setting-up.livemd)\n3. [Index](./../../index.livemd)\n4. [Index_docs](./../../index_docs.livemd)\n5. [Visualization](./../../visualization.livemd)\n   1. [Actors](./../../visualization/actors.livemd)\n6. [Vm_interface](./../../vm_interface.livemd)","ref":"writing-tests.html#index"},{"type":"extras","title":"Conventions - Writing Tests","doc":"Since the [figuring out](./understanding.livemd) page demonstrates that well laid out test files are the key to understanding how modules work, it is important to write tests so this can always be achieved.\n\nThe following sections will lay out how we can achieve this.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#conventions"},{"type":"extras","title":"Make sure names from the test matches setup_all - Writing Tests","doc":"```elixir\nExUnit.start()\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Nam do\n  use ExUnit.Case\n\n  setup_all do\n    special = 3\n    [special: special]\n  end\n\n  test \"this is acceptable\", %{special: special} do\n    assert special == 3\n  end\n\n  test \"this test is not acceptable\", %{special: spec} do\n    assert spec == 3\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Nam, <<70, 79, 82, 49, 0, 0, 14, ...>>,\n {:\"test this test is not acceptable\", 1}}\n```\n\nIf this convention is not followed, then the user can not simply be\ncopy and paste the lines to figure out how to use the module.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#make-sure-names-from-the-test-matches-setup_all"},{"type":"extras","title":"Write setup_all to not crash on reevaluation - Writing Tests","doc":"```elixir\ndefmodule AnomaTest.LiveBook.NoCrash do\n  use ExUnit.Case\n\n  setup_all do\n    name = :intent_example\n\n    unless Process.whereis(name) do\n      Anoma.Node.Intent.init(name)\n    end\n\n    [intent_pool: name]\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nwarning: Anoma.Node.Intent.init/1 is undefined (module Anoma.Node.Intent is not available or is yet to be defined)\n  documentation/contributing/testing.livemd#cell:qbrtwwd53rvqgtpz:8: AnomaTest.LiveBook.NoCrash.__ex_unit_setup_all_0/1\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.NoCrash, <<70, 79, 82, 49, 0, 0, 11, ...>>,\n {:__ex_unit_setup_all_0, 1}}\n```\n\n* Here we check if the process is running. This way if it is\n  already in IEX we simply don't disturb it but rename it to point\n  to the correct one we wish to operate over.\n* If we did not do this check the other commands may fail and IEX\n  may not be trapped to continue.\n* `mix test` will not catch this\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#write-setup_all-to-not-crash-on-reevaluation"},{"type":"extras","title":"Try to make tests idempotent - Writing Tests","doc":"Let us demonstrate this point, by making a simple queue service.\n\n```elixir\ndefmodule Queue do\n  use GenServer\n\n  def init(_init) do\n    {:ok, :queue.new()}\n  end\n\n  def start_link(arg) do\n    GenServer.start_link(__MODULE__, arg, name: arg)\n  end\n\n  def reset(queue) do\n    GenServer.cast(queue, :reset)\n  end\n\n  def enqueue(queue, name) do\n    GenServer.cast(queue, {:enqueue, name})\n  end\n\n  def pop(queue) do\n    GenServer.call(queue, :pop)\n  end\n\n  def handle_cast(:reset, _pool) do\n    {:noreply, :queue.new()}\n  end\n\n  def handle_cast({:enqueue, val}, pool) do\n    {:noreply, :queue.cons(val, pool)}\n  end\n\n  def handle_call(:pop, _from, queue) do\n    {:reply, :queue.get_r(queue), :queue.drop_r(queue)}\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, Queue, <<70, 79, 82, 49, 0, 0, 18, ...>>, {:handle_call, 3}}\n```\n\n```elixir\ndefmodule AnomaTest.LiveBook.Idempotent do\n  use ExUnit.Case\n\n  setup_all do\n    name = :queue_name\n\n    unless Process.whereis(name) do\n      Queue.start_link(name)\n    end\n\n    [queue: name]\n  end\n\n  test \"reset\", %{queue: name} do\n    # Make sure we get reliable results!\n    Queue.reset(name)\n    Queue.enqueue(name, 5)\n    Queue.enqueue(name, 4)\n    assert 5 == Queue.pop(name)\n  end\nend\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:module, AnomaTest.LiveBook.Idempotent, <<70, 79, 82, 49, 0, 0, 15, ...>>, {:\"test reset\", 1}}\n```\n\nHere before getting values from the queue, we make sure it's fresh by resetting it.\n\nIn the `Queue` case it's contrived, however a lot of genservers in the codebase work like this!\n\nSomething important to note is that `mix test` will not catch this!\n\nSo please try to keep tests isolated from each other.\n\n<!-- livebook:{\"branch_parent_index\":1} -->","ref":"writing-tests.html#try-to-make-tests-idempotent"},{"type":"extras","title":"Try to Name Values - Writing Tests","doc":"For debugging purposes, it is best to name values, and so you can rerun values on command, or help the debugging process.","ref":"writing-tests.html#try-to-name-values"},{"type":"extras","title":"Understanding any code in Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Understanding any code in Anoma","ref":"understanding.html"},{"type":"extras","title":"Index - Understanding any code in Anoma","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"understanding.html#index"},{"type":"extras","title":"Figuring out what a module does - Understanding any code in Anoma","doc":"Α good start is by calling `h` on the module from within one's IEX\ninstance.\n\n```elixir\nrequire IEx.Helpers\nimport IEx.Helpers\n# the above two lines are not requried for the REPL!\nh(Anoma.Node)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n\n                                   Anoma.Node\n\nI act as a registry for Anoma Nodes","ref":"understanding.html#figuring-out-what-a-module-does"},{"type":"extras","title":"Required Arguments - Understanding any code in Anoma","doc":"• name - name for this process\n  • snapshot_path : [atom() | 0]\n    • A snapshot location for the service (used in the worker)\n\n  • storage : Anoma.Storage.t() - The Storage tables to use\n  • block_storage - a location to store the blocks produced","ref":"understanding.html#required-arguments"},{"type":"extras","title":"Optional Arguments - Understanding any code in Anoma","doc":"• jet : Nock.jettedness() - how jetted the system should be\n  • old_storage : boolean - states if the storage should be freshly made\n    • by default it is false","ref":"understanding.html#optional-arguments"},{"type":"extras","title":"Registered names - Understanding any code in Anoma","doc":"#","ref":"understanding.html#registered-names"},{"type":"extras","title":"Created Tables - Understanding any code in Anoma","doc":"• storage.qualified\n  • storage.order\n  • block_storage\n\n```\n\nHowever, this typically doesn't show off how one uses said\nmodule. Thankfully, the codebase is setup in such a way that one can\nalways interactively play with any given module.\n\nThis is done by simply checking out the tests folder, and finding the\nmodule you wish to learn to learn about.\n\nFor example, let us learn about the mempool. In the codebase currently\nthis can be found here:\n\n* `test/node/mempool_test.exs`,\n\nnote that even if this gets out of date, you should be able to do this with any file!\n\nThe first thing one can do to run things interactively is by taking\nall the imports of the file and running it locally\n\nIn this case I input the following from the file into IEX.\n\nI also make sure to include an extra `import ExUnit.Assertions` so\nthat assertions can be copied and pasted to IEX\n\n```elixir\n# output redacted for length\nalias Anoma.Storage\nalias Anoma.Node.Storage.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\n\nimport TestHelper.Nock\n\nimport ExUnit.Assertions\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\nExUnit.Assertions\n```\n\nAfter the imports are done, then we copy the `setup_all` if this section\nexists\n\n```elixir\n# setup_all do\nstorage = %Anoma.Storage{\n  qualified: AnomaTest.Mempool.Qualified,\n  order: AnomaTest.Mempool.Order\n}\n\nname = :mempool\nsnapshot_path = [:my_special_nock_snaphsot | 0]\n\nnode = Anoma.Node.state(name)\n\nunless Process.whereis(:mempool_mempool_com) do\n  Anoma.Node.start_link(\n    name: name,\n    snapshot_path: snapshot_path,\n    storage: storage,\n    block_storage: :mempool_blocks\n  )\nend\n\nnode\n# end\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%Anoma.Node{\n  logger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Logger 0UFKnKepVKxm8B1uH/QkoKh0hLuVQ8TrRGf+4dFY+Zw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<49, 47, 91, 248, 87, 123, 100, 79, 0, 37, 176, 239, 240, 27, 218, 11, 63, 251, 170,\n        244, 75, 20, 116, 142, 149, 64, 1, 81, 42, 139, 210, 44>>,\n      sign: <<209, 65, 74, 156, 167, 169, 84, 172, 102, 240, 29, 110, 31, 244, 36, 160, 168, 116,\n        132, 187, 149, 67, 196, 235, 68, 103, 254, 225, 209, 88, 249, 156>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  clock: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Clock qoWUQLrfe8KstPBZsIN9e6Escpvdu5LbUUCS1SoGVYw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<141, 195, 214, 28, 18, 243, 25, 172, 222, 0, 152, 202, 137, 215, 147, 57, 71, 196,\n        13, 93, 148, 71, 58, 222, 4, 173, 137, 126, 228, 55, 181, 48>>,\n      sign: <<170, 133, 148, 64, 186, 223, 123, 194, 172, 180, 240, 89, 176, 131, 125, 123, 161, 44,\n        114, 155, 221, 187, 146, 219, 81, 64, 146, 213, 42, 6, 85, 140>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  pinger: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Pinger QeQQ09SN+5MeUCoc5hrKec7jJhKcrtSt+g879DFP0aY=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<98, 214, 175, 27, 239, 163, 208, 126, 208, 197, 212, 140, 32, 152, 249, 1, 180,\n        245, 181, 143, 171, 251, 99, 160, 21, 174, 16, 128, 35, 100, 227, 75>>,\n      sign: <<65, 228, 16, 211, 212, 141, 251, 147, 30, 80, 42, 28, 230, 26, 202, 121, 206, 227, 38,\n        18, 156, 174, 212, 173, 250, 15, 59, 244, 49, 79, 209, 166>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  mempool_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<111, 103, 214, 144, 51, 40, 198, 132, 2, 11, 19, 47, 228, 153, 121, 250, 201, 147,\n        248, 105, 164, 121, 218, 177, 11, 155, 204, 208, 20, 202, 55, 12>>,\n      sign: <<248, 79, 247, 60, 208, 85, 198, 79, 222, 145, 122, 214, 201, 141, 145, 255, 218, 208,\n        168, 250, 173, 25, 37, 111, 214, 134, 93, 99, 36, 0, 154, 28>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  mempool: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Mempool KNPB2ijsWnfve4L8Iuq434po8eFCJNK+EvKQ4Vd2Tqw=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<167, 148, 18, 166, 207, 244, 170, 202, 95, 3, 187, 9, 217, 157, 97, 177, 208, 76,\n        163, 136, 148, 60, 160, 248, 68, 61, 142, 67, 47, 229, 82, 30>>,\n      sign: <<40, 211, 193, 218, 40, 236, 90, 119, 239, 123, 130, 252, 34, 234, 184, 223, 138, 104,\n        241, 225, 66, 36, 210, 190, 18, 242, 144, 225, 87, 118, 78, 172>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  executor_topic: %Anoma.Node.Router.Addr{\n    server: nil,\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<250, 161, 209, 10, 200, 171, 194, 37, 114, 235, 167, 193, 45, 245, 92, 157, 121,\n        106, 195, 86, 139, 58, 214, 217, 105, 181, 51, 76, 178, 55, 240, 37>>,\n      sign: <<188, 255, 80, 242, 172, 114, 141, 55, 239, 90, 234, 3, 38, 172, 76, 203, 220, 62, 127,\n        225, 249, 184, 214, 101, 227, 76, 95, 88, 235, 190, 14, 58>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  },\n  executor: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Executor zdsJtoPjG67QStGoPdiqdjF8wYg5J8Op5i1Bx9V2HCc=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<161, 173, 246, 156, 52, 73, 176, 104, 173, 192, 224, 111, 212, 231, 14, 136, 230,\n        151, 241, 237, 239, 180, 127, 69, 59, 149, 86, 210, 133, 246, 106, 20>>,\n      sign: <<205, 219, 9, 182, 131, 227, 27, 174, 208, 74, 209, 168, 61, 216, 170, 118, 49, 124,\n        193, 136, 57, 39, 195, 169, 230, 45, 65, 199, 213, 118, 28, 39>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  ordering: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Storage.Ordering oCXn2nJdaIIF+wTv8PreeZ56RXH6TKNVH2Vk+EP4FzI=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<137, 234, 55, 245, 216, 126, 69, 133, 161, 185, 181, 4, 138, 160, 234, 238, 82,\n        157, 113, 175, 169, 23, 67, 177, 90, 99, 60, 94, 0, 237, 51, 53>>,\n      sign: <<160, 37, 231, 218, 114, 93, 104, 130, 5, 251, 4, 239, 240, 250, 222, 121, 158, 122,\n        69, 113, 250, 76, 163, 85, 31, 101, 100, 248, 67, 248, 23, 50>>\n    },\n    router: %Anoma.Node.Router.Addr{\n      server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n      id: %Anoma.Crypto.Id.Extern{\n        encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n          128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n        sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n          24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n      },\n      router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n    }\n  },\n  router: %Anoma.Node.Router.Addr{\n    server: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\",\n    id: %Anoma.Crypto.Id.Extern{\n      encrypt: <<94, 28, 181, 242, 67, 161, 117, 206, 37, 31, 232, 223, 176, 59, 233, 72, 171, 91,\n        128, 32, 13, 85, 217, 89, 101, 177, 80, 142, 50, 59, 42, 36>>,\n      sign: <<30, 209, 148, 133, 48, 20, 5, 203, 237, 177, 99, 155, 147, 145, 153, 163, 128, 231,\n        24, 41, 194, 1, 227, 145, 247, 139, 243, 222, 78, 176, 193, 158>>\n    },\n    router: :\"Anoma.Node.Router HtGUhTAUBcvtsWObk5GZo4DnGCnCAeOR94vz3k6wwZ4=\"\n  }\n}\n```\n\nFrom here we can run any tests in the file by copying those as well!\n\nWhat is even better is that we can copy parts of tests to setup an\narea to play with the code to figure out what is going well with our\nother tools.\n\nThis is a great way for learning any API in the codebase as you can\nget hands on what each function and message does.\n\n```elixir\n# test \"successful process\", %{node: node} do\nkey = 555\nstorage = Ordering.get_storage(node.ordering)\nincrement = increment_counter_val(key)\nzero = zero_counter(key)\n\n:ok =\n  Router.call(\n    node.router,\n    {:subscribe_topic, node.executor_topic.id, :local}\n  )\n\nMempool.hard_reset(node.mempool)\n\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n\nMempool.execute(node.mempool)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nFurther since the data is live, we can use tools like `:observer` to\nview the processes, and see general state dumping commands.\n\nFor databases I've found that `Anoma.Mnesia` is a good tool along with\n`:observer` for seeing what is currently in database table.","ref":"understanding.html#created-tables"},{"type":"extras","title":"Visualizing Anoma","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Visualizing Anoma","ref":"visualization.html"},{"type":"extras","title":"Index - Visualizing Anoma","doc":"1. [Contributing](./CONTRIBUTING.livemd)\n   1. [Git](./contributing/git.livemd)\n   2. [Hoon](./contributing/hoon.livemd)\n   3. [Iex](./contributing/iex.livemd)\n   4. [Observer](./contributing/observer.livemd)\n   5. [Testing](./contributing/testing.livemd)\n      1. [Running Tests](./contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n   6. [Understanding](./contributing/understanding.livemd)\n2. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n3. [Index](./index.livemd)\n4. [Index_docs](./index_docs.livemd)\n5. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n6. [Vm_interface](./vm_interface.livemd)","ref":"visualization.html#index"},{"type":"extras","title":"Note on this section - Visualizing Anoma","doc":"This section provides extra visual diagrams on various components of\nAnoma, and serves to give an intuitive understanding on how Anoma\nworks.","ref":"visualization.html#note-on-this-section"},{"type":"extras","title":"The Actors","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# The Actors","ref":"actors.html"},{"type":"extras","title":"Index - The Actors","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"actors.html#index"},{"type":"extras","title":"An overview of Anoma - The Actors","doc":"A good overview of Actors can be seen by looking at the supervision tree of Anoma itself.\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Storage.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```","ref":"actors.html#an-overview-of-anoma"},{"type":"extras","title":"Mempool - The Actors","doc":"A good view of visualizing Anoma can be seen through running the\nmempool, as it orchastrates the other actors in Anoma to act\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFirst we will create a transaction and see how that changes the base supervision tree before executing\n\n```elixir\nalias Anoma.Storage\nalias Anoma.Node.Storage.Ordering\nalias Anoma.Node.Mempool\nalias Anoma.Node.Router\nimport TestHelper.Nock\n\nstorage = %Anoma.Storage{\n  qualified: Anoma.Qualified,\n  order: Anoma.Order\n}\n\nname = :anoma\nnode = Anoma.Node.state(name)\nkey = 555\nzero = zero_counter(key)\npid_zero = Mempool.tx(node.mempool, {:kv, zero}).pid\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.438.0>\n```\n\nThe previous evaluations PID can be seen in the diagram below!\n\n```elixir\n{_, [pid1, pid2]} = Process.info(Process.whereis(:anoma), :links)\nKino.Process.render_sup_tree(pid2, direction: :left_right)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\ngraph LR;\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 1(Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 2(Anoma.Node.Clock plaqCqOIQ4LLCT9MAmEMV+qkqZq4+qZV2KSpqSxRZu0=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 3(Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 4(Anoma.Node.Storage.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 5(Anoma.Node.Executor po4ivXyVtjQ9jvTtra0D2DbKIpM8YOClCmfk8JLp31k=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 6(Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=):::worker\n0(supervisor hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=):::root ---> 7(Anoma.Node.Pinger Oc96nqV6/0FFT/JULG5Ep+Z1c62/8f1Bi0gY9CVmJhs=):::worker\nclassDef root fill:#c4b5fd, stroke:#374151, stroke-width:4px;\nclassDef supervisor fill:#c4b5fd, stroke:#374151, stroke-width:1px;\nclassDef worker fill:#93c5fd, stroke:#374151, stroke-width:1px;\nclassDef notstarted color:#777, fill:#d9d9d9, stroke:#777, stroke-width:1px;\n\n\n```\n\nNow let us see what happens between the actors when we run the mempool\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn ->\n    Mempool.execute(node.mempool)\n  end,\n  message_label: &Anoma.Node.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```mermaid\nsequenceDiagram\nparticipant 3 AS code_server;\nparticipant 7 AS mnesia_locker;\nparticipant 6 AS mnesia_tm;\nparticipant 8 AS Anoma.Node.Router hWXJ+NujE76g6g4X5Bu+KH1YtSKrur7yDUfeu0JguKY=;\nparticipant 2 AS Anoma.Node.Logger BDTPKlJ5ubxM9NMrbgMzxE5jfKKn+qwnxISeroCw3xc=;\nparticipant 4 AS Anoma.Node.Storage.Ordering rVQnNBPLju9VBsHOQzAdKaEXRK2u03vF8huvKzVPyT8=;\nparticipant 1 AS Anoma.Node.Mempool yg3U9BqClfT+jJkwbtuYm2WCmIgR+f6ELjodD5P4eko=;\nparticipant 0 AS self();\nparticipant 5 AS #35;PID<0.438.0>;\n0->>1: CALL: execute\n1->>2: ADD LEVEL: info\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>4: CALL: next_order\n4->>1: INFO: tuple\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>3: INFO: code_call\n3->>1: INFO: code_server\n1->>2: ADD LEVEL: info\n1->>4: CALL: new_order\n4->>1: INFO: tuple\n1->>2: ADD LEVEL: info\n1->>5: INFO: write_ready\n1->>2: ADD LEVEL: info\n1->>6: INFO: tuple\n6->>1: INFO: mnesia_tm\n1->>7: INFO: tuple\n7->>1: INFO: mnesia_locker\n1->>7: INFO: release_tid\n1->>6: INFO: delete_transaction\n1->>2: ADD LEVEL: info\n1->>2: ADD LEVEL: info\n1->>8: CAST: cast\n1->>0: INFO: tuple\n\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n{:ok, 1}\n```\n\nAs we can see, we get a fairly solid overview of what actors sent what messages\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe can also see what processes startup when we start an execution\n\n```elixir\nKino.Process.render_seq_trace(\n  [Process.whereis(node.mempool.server)],\n  fn -> Mempool.tx(node.mempool, {:kv, increment_counter_val(555)}).pid() end,\n  message_label: &Anoma.Node.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n#PID<0.1147.0>\n```\n\n```elixir\nKino.Process.render_seq_trace(\n  :all,\n  fn -> Anoma.Node.Logger.add(node.logger, :info, \"help\") end,\n  message_label: &Anoma.Node.Utility.message_label/1\n)\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n:ok\n```","ref":"actors.html#mempool"},{"type":"extras","title":"Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Hoon","ref":"hoon-2.html"},{"type":"extras","title":"Index - Hoon","doc":"1. [Contributing](./CONTRIBUTING.livemd)\n   1. [Git](./contributing/git.livemd)\n   2. [Hoon](./contributing/hoon.livemd)\n   3. [Iex](./contributing/iex.livemd)\n   4. [Observer](./contributing/observer.livemd)\n   5. [Testing](./contributing/testing.livemd)\n      1. [Running Tests](./contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./contributing/testing/writing-tests.livemd)\n   6. [Understanding](./contributing/understanding.livemd)\n2. [Hoon](./hoon.livemd)\n   1. [Calling](./hoon/calling.livemd)\n   2. [Dumping](./hoon/dumping.livemd)\n   3. [Setting Up](./hoon/setting-up.livemd)\n3. [Index](./index.livemd)\n4. [Index_docs](./index_docs.livemd)\n5. [Visualization](./visualization.livemd)\n   1. [Actors](./visualization/actors.livemd)\n6. [Vm_interface](./vm_interface.livemd)","ref":"hoon-2.html#index"},{"type":"extras","title":"About This Guide - Hoon","doc":"This guide hopefully serves you to be able to reason about the nock\ncode in Anoma. It is written for a non Hoon audience, so if you are\nfamiliar with Hoon, you may find use in the Nock code as there is a\nbig emphesis on nock itself, rather than just Hoon. If you are not\nfamiliar with Hoon, this merely shows you how to use the\n[Urbit](https://urbit.org/) environment to aid Nock code.\n\nA good general guide to Hoon can be found [At the Hoon School](https://developers.urbit.org/guides/core/hoon-school).\nHopefully the documention here serves as a good companion piece for\nanyone interested in Nock, Hoon, or Anoma.","ref":"hoon-2.html#about-this-guide"},{"type":"extras","title":"Calling","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Calling","ref":"calling.html"},{"type":"extras","title":"Index - Calling","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"calling.html#index"},{"type":"extras","title":"Calling Conventions - Calling","doc":"For this section, it is assumed that one is comfortable with the techniques outlined in the [dumping guide](./dumping.livemd), in particular familiarity with:\n\n1. [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar)\n2. [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis)\n\nis had, if one is uncomfortable with what is shown here, it would be a good idea to skim back over the [dumping guide](./dumping.livemd) for more information.\n\nWith that disclaimer out of the way, let us talk about calling conventions.","ref":"calling.html#calling-conventions"},{"type":"extras","title":"Basic Nock Calls - Calling","doc":"There are a few ways to call Nock functions, recall that the structure of a functions look like this:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThus if we wish to call our code example, the most basic way is by invoking nock `9`. Continuing our example from above, let us see the most basic call of it.\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 0 1]\n777\n```\n\nTo better understand what the `9` is doing let us ask us the nock structure of it\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]]\n```\n\nHere we can see the `9` takes 2 arguments, a `p=2` and a `q=[0 1]` argument.\n\nThe `q=[0 1]` argument goes off first. The point of this is to determine what module/layer (called an [core](https://developers.urbit.org/reference/glossary/core) in hoon) the particular function (called a [gate](https://developers.urbit.org/reference/glossary/gate) in hoon) belongs to.\n\nFrom here the `p=2` is the location of the function/[gate](https://developers.urbit.org/reference/glossary/gate).\n\nIn our example we know the function is indexed at 2, so thus we simply call the logic with the environment it's defined inside, meaning we simply get out the `6`th index which we have observed above is 777\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n`[9 2 0 1]` isn't too interesting on it's own, all we have managed to do, is make fancy default values.\n\nHowever, since the logic we are running indexs into the sample, all we have to do is fine a formula that replaces the sample with the desired value\n\n```hoon\n> .*  [[0 6] 777 999]  [9 2 10 [6 1 888] 0 1]\n888\n> ;;  nock  [9 2 10 [6 1 888] 0 1]\n[%9 p=2 q=[%10 p=[p=6 q=[%1 p=888]] q=[%0 p=1]]]\n```\n\nAbove we do exactly that, all it took was adding a simple `10 [6 1 888]`, however let us analyze what this does.\n\n`%10` is better known as replace at axis, the axis is the first value of `[6 1 888]` which in this case is position `6`. We then run the formula `[1 888]` which is simply saying return the constant `888`, then `10` finishes and replaced position `6` with the result, giving the logic located at `2` (I.E. `[0 6]`) the new sample to run against.\n\nSince the `%9`'s `q=...` has the replaced value, this ends up being the context for the `p=2` to run inside, and thus we have a computation that is effectively:\n\n```hoon\n> .*  [[0 6] 888 999] [9 2 0 1]\n888\n```\n\nWe will in the next section see how Hoon functions are defined, as they give further detail in how we use instruction `9`.","ref":"calling.html#basic-nock-calls"},{"type":"extras","title":"Hoon Gates: What are they really? - Calling","doc":"Something interesting is comparing the `9` described here to [dumping the indicies found in the dumping guide](./dumping.livemd#dumping-indexing-offsets).\n\nNamely we saw:\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nWhat is incongruous, is that we described `9` as calling a function, but in the dumping section, we make it seem like it's effectively only doing indexing to bring the name ready to be called.\n\nThis all has to do with how hoon stores nock functions, they do something quite clever.\n\nInstead of just storing the function as code itself, it stores it similarly to this\n\n```hoon\n[[1 [[0 6] 777 999]] 666 909]\n```\n\nWhere we store a nock function that evaluates to the code, the `1` instruction is simply that, when we evaluate this form we get\n\n```hoon\n> .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]\n[[0 6] 777 999]\n```\n\nfor which we can now call it\n\n```hoon\n> .*  .*  [[1 [[0 6] 777 999]] 666 909]  [9 2 0 1]  [9 2 0 1]\n777\n```\n\nIn this case, it doesn't do much, but it makes sense if we look at a real example.\n\n```hoon\n> .*  add:anoma  [0 2]\n[ 6\n  [5 [1 0] 0 12]\n  [0 13]\n  9\n  2\n  10\n  [6 [8 [9 342 0 7] 9 2 10 [6 0 28] 0 2] 4 0 13]\n  0\n  1\n]\n```\n\nOn this example I want to focus on the `dec` call `[8 [9 342 0 7] 9 2 10 ...]`. We know this is dec, as we already know it's offset inside layer 1 is `342`, but it's located at `7` as we've pushed `add` with its sample to the tree, making layer 1's index go to 7 (see the [section on how indicies change](./dumping.livemd#how-index-of-layers-change)) relative to `add`.\n\nWhat is very interesting, is that since the [gate](https://developers.urbit.org/reference/glossary/gate) evaluates to the nock function we wish, we can follow it up with the simple `[9 2 10 [6 ...] 0 ...]` pattern we found before.\n\nMeaning that we have decoupled indexing with calling. If Hoon did not do this, then we are in an awkward position that the `[9 342 0 7]` somehow has to get `0 7` index before running the application change `0 28`, complicating the formula. Making it a simple constant function allows the formulas to stay manageable.\n\nSome other minor notes. The call: `[9 2 10 [6 0 28] 0 2]` ends with `0 2` instead of `0 1` because we have bushed with `8`, more on this later.\n\nWe will continue to expand this in the next section, but first let us learn how to evaluate code in the context of Anoma as the standard environment.","ref":"calling.html#hoon-gates-what-are-they-really"},{"type":"extras","title":"Evaluating Calls in The Anoma Context - Calling","doc":"For actually writing code for Anoma, the dump of dec that we saw:\n\n```\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nwould not actually run in the Anoma standard library. This is because it is assuming the current environment which has the Hoon standard library.\n\n```hoon\n> .*  anoma  [7 [0 46] 9 342 0 15]\ndojo: hoon expression failed\n```\n\nRather than by hand editing the `7 [0 46]` out, we can instead tell Hoon that the context of the computation is in Anoma, and this is done through [tisgar(=>)](https://developers.urbit.org/reference/hoon/rune/tis#-tisgar).\n\nA good example can be seen here:\n\n```hoon\n> =>  anoma  !=(dec)\n[9 342 0 15]\n```\n\nWhich gives us the correct computation to run dec on Anoma.\n\n```hoon\n> =>  anoma  .*  .  [9 342 0 15]\n[ [ 6\n    [5 [1 0] 0 6]\n...\n:: dec core emitted\n\n> =>  anoma  .*  .*  .  [9 342 0 15]  [9 2 10 [6 1 777] 0 1]\n776\n```","ref":"calling.html#evaluating-calls-in-the-anoma-context"},{"type":"extras","title":"What a Hoon function call actually does - Calling","doc":"So far this document has only outlined calling Hoon functions by hand, but what does the cannonical application form generate?\n\n```hoon\n> =>  anoma  (dec 3)\n2\n```\n\nWell we can ask [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) what this expression means\n\n```hoon\n> =>  anoma  !=((dec 3))\n[8 [9 342 0 15] 9 2 10 [6 7 [0 3] 1 3] 0 2]\n> ;;  nock  =>  anoma  !=((dec 3))\n[ %8\n  p=[%9 p=342 q=[%0 p=15]]\n  q=[%9 p=2 q=[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[%0 p=2]]]\n]\n```\n\nLet us break down this expression\n\n1. `[%8 p=[9 342 ...] q=[9 2 ...]]`\n   * `8` simply does a push on subject, with the `p` getting consed onto the environment. We've seen this `p` before, it is simply the formula for `dec`.\n   * Thus after the `p` we have `[dec anoma]` filling the environment\n   * This is now the context for the `q=`\n2. `[%9 p=2 q=[%10 ...]]`\n   * We've seen this `[9 2 10 [6 ...] ...]` call before, like before the function within the current layer is located at 2. However what is different is the specifics of the `q`\n3. `[%10 p=[p=6 q=[%7 p=[%0 p=3] q=[%1 p=3]]] q=[0 2]]`\n   * This 10 is a replace at axis 6 like we have seen before, but let us note the `q=[0 2]`.\n   * Most example's we've seen have been `[0 1]`, this example has a `[0 2]` as the first `%8` pushed the `dec` function onto the environment, meaning that the function we wish to replace `6` of is really at index 2!\n   * An important note is that this rule expands to a replace where the `q` and `p` are ran on the original environment.\n   * This means that `q=[%7 ...]` gets to run in the environment where the surrounding environment still exists\n4. `[%7 p=[%0 p=3] q=[%1 p=3]]`\n   * Here are where things get interesting, `%7` is simply composition, thus `p` is ran on the environment then `q` is.\n   * This is important because the `p=[%0 p=3]` simply restores the original environment\n     ```hoon\n     > .*  999  [8 [1 1] 0 1]\n     [1 999]\n     > .*  999  [8 [1 1] 0 3]\n     999\n     ```\n   * Meaning that computation `q` can be ran as if the `%8` never happened.\n   * The Hoon compiler is sometimes smart and will optimize out the `%7`\n5. `[%1 p=3]`\n   * We simply put 3 as the argument\n   * Dec now runs with 3 as we expect.\n\nThus as we can see, the calling convention of Hoon is not very complicated, and is mostly sensible about trying to preserve the environments things are called in.","ref":"calling.html#what-a-hoon-function-call-actually-does"},{"type":"extras","title":"Paramarterized Modules: Or How Gates are just Cores - Calling","doc":"A common occurence in our standard library is the use of paramartized modules. However something interesting to note is that on the [gate](https://developers.urbit.org/reference/glossary/gate) documentation, it mentions\n\n> A [gate](https://developers.urbit.org/reference/glossary/gate) is [core](https://developers.urbit.org/reference/glossary/core) with one arm named $ (buc). They are often called Hoon functions because they have many of the same properties of functions from other programming languages.\n\nMeaning that every time we have been calling `add` we've really been calling a module with a function named $ inside\n\n```hoon\n> =>  anoma  $:add\n0\n```\n\nThus the calling conventions we've discussed above are exactly the same for modules!\n\nLet us look at the `lsh` function for confirmation\n\n```hoon\n> =>  anoma  !=(block)  ::  layer 4\n[9 10 0 1]\n> =>  anoma  !=(lsh:block)\n[7 [9 10 0 1] 9 90 0 1]\n> =>  anoma  !=((lsh:block 3 4))\n[8 [7 [9 10 0 1] 9 90 0 1] 9 2 10 [6 [7 [0 3] 1 3] 7 [0 3] 1 4] 0 2]\n```\n\nWe can see here that block is located at index `10` inside of the anoma environment. Also note the `9` call, we are calling block to bring it to the front!\n\nnext we check `lsh` which is located `90` within it, nothing out of the ordinary. We use `%7` to compose the indexing into the structure, which is reasonable.\n\nWhen we call `lsh` on `3` and `4` the result is exactly like we expect, we generate out the `%8` call that we disected above.\n\nSo we can already call the `lsh` function as if no paramartized was had. This makes sense as we know that each [gate](https://developers.urbit.org/reference/glossary/gate) has a sample that it takes if no substitution is had.\n\nNow let us replace the default block value with `999` (note you don't want to run this, it'll be too slow)\n\n```hoon\n> =>  anoma  !=((~(lsh block 999) 3 4))\n[ 8\n  [8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]\n  9\n  2\n  10\n  [6 [7 [0 3] 1 3] 7 [0 3] 1 4]\n  0\n  2\n]\n```\n\nThe only difference that was had was in in  `[8 [9 10 0 1] 9 90 10 [6 7 [0 3] 1 999] 0 2]`. The rest of the formula stayed the same.\n\nHowever looking at this change, this should not be very shocking, as we have analyzed with the function above, we are simply pushing `block` to the front of the env with the `[8 [9 10 0 1] ...]`, leaing the environment being `[block anoma]`, then we simply wish to call `90` where `lsh` is located with the `6` index of the `block` environment being set to `999`.\n\nNote the `6` index is a gate's argument which we can see with this call:\n\n```hoon\n> =>  anoma  !=(block-size:block)\n[7 [9 10 0 1] 0 6]\n```\n\nThen we simply compute the rest of `lsh` with the default value being 999. Using a non large number we can see how this changes the results.\n\n```hoon\n> =>  anoma  (~(lsh block 1) 3 4)\n256\n> =>  anoma  (~(lsh block 0) 3 4)\n32\n> =>  anoma  (lsh:block 3 4)\n32\n```","ref":"calling.html#paramarterized-modules-or-how-gates-are-just-cores"},{"type":"extras","title":"Dumping","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Dumping\n\n```elixir\nMix.install([\n  {:kino_vega_lite, \"~> 0.1.10\"}\n])\n```","ref":"dumping.html"},{"type":"extras","title":"Index - Dumping","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"dumping.html#index"},{"type":"extras","title":"Dumping Nock - Dumping","doc":"Given a functioning Hoon environment with Anoma loaded, we can now start [dumping](https://en.wikipedia.org/wiki/Core_dump) various data in the environment.\n\nThis guide hopefully serves as a good way to give you the tools needed to [dump](https://en.wikipedia.org/wiki/Core_dump) anything for yourself.","ref":"dumping.html#dumping-nock"},{"type":"extras","title":"Dumping Functions - Dumping","doc":"[Dumping](https://en.wikipedia.org/wiki/Core_dump) any [Hoon gate](https://developers.urbit.org/reference/glossary/gate) is relatively easy.\n\nHowever, first we need to learn how to get Hoon to let us use Nock properly. A good way is by reading the [dot(.)](https://developers.urbit.org/reference/hoon/rune/dot) section, as [runes](https://developers.urbit.org/reference/hoon/rune) starting with `.` deal with nock operations.\n\nIn particular we wish to focus on [dottar(.*)](https://developers.urbit.org/reference/hoon/rune/dot#-dottar), which deals with calling nock on some expression.\n\nWe won't go into detail about calling functions in this section, however there is another section that focuses solely on how to call functions and how it works in Nock.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nSpeaking of functions, we should know just a few things about the layout of functions, and their important indicies.\n\nFunctions in Hoon are laid out as the following:\n\n```nock\n[function sample environment-defined-in]\n```\n\n* _Function_ is some nock logic we wish to run\n* _Sample_ is the default argument of the function if non is given\n* _Environment-defined-in_ is the environment the function is defined in and relies upon.\n\nA good basic example can be seen below:\n\n```hoon\n[[0 6] 777 999]\n```\n\nThis function has an arbitrary environment of `999` and a sample of `777`. The logic itself simply grabs the sample from the environment.\n\nA good visualization of the indexing can be seen below\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n2 --> 4\n2 --> 5\n3 --> 6\n3 --> 7\n```\n\nwhere we have in our concrete example\n\n| Index | Nock              |\n| ----- | ----------------- |\n| 1     | `[[0 6] 777 999]` |\n| 2     | `[0 6]`           |\n| 3     | `[777 999]`       |\n| 4     | `0`               |\n| 5     | `6`               |\n| 6     | `777`             |\n| 7     | `999`             |\n\nWith some basics out of the way, let us get to [dumping](https://en.wikipedia.org/wiki/Core_dump) hoon functions!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nWe shall dump the most basic of functions, decrement!\n\nWe can do this simply by bringing decrement to the front of the environment, and getting it in the function form of `[function sample environment]` we saw before. We can do this by simply stating the name of the function we wish, and then get the function out of it by getting the second index!\n\nNote that Hoon uses `function:module` (`f:mn:...:m1`) form.\n\n```nock\n.*  dec:anoma  [0 2]\n[6 [5 [1 0] 0 6] [0 0] 8 [1 0] 8 [1 6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1] 9 2 0 1]\n```\n\nThe logic here doesn't particularly matter, but here we have the nock definiton of decrement, which is wonderful!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nThis can be done to any function, regardless of how nested the modules are\n\n```hoon\n> .*  lsh:block:anoma  [0 2]\n[ 8\n  [9 4 0 255]\n  9\n  2\n  10\n  [6 [0 29] 7 [0 3] 8 [9 4 0 31] 9 2 10 [6 7 [0 3] 8 [9 4 0 255] 9 2 10 [6 [7 [0 3] 9 182 0 7] 0 28] 0 2] 0 2]\n  0\n  2\n]\n```","ref":"dumping.html#dumping-functions"},{"type":"extras","title":"Casting to Nock, a useful tool - Dumping","doc":"A good way to visualize the dump, is by casting the result to nock\n\n```hoon\n> ;;  nock  [9 2 0 1]\n[%9 p=2 q=[%0 p=1]\n```\n\nthe `p`'s and `q`'s are arguments and the `%9` and `%0` are the nock instructions being ran.\n\nFrom here, the [instruction set can be consluted for the meaning of any particular instruction](https://developers.urbit.org/reference/nock/definition#instructions).\n\n```hoon\n> ;;  nock  .*  dec.anoma  [0 2]\n[ %6\n  p=[%5 p=[%1 p=0] q=[%0 p=6]]\n  q=[%0 p=0]\n  r=[%8 p=[%1 p=0] q=[%8 p=[%1 p=[6 [5 [0 30] 4 0 6] [0 6] 9 2 10 [6 4 0 6] 0 1]] q=[%9 p=2 q=[%0 p=1]]]]\n]\n```","ref":"dumping.html#casting-to-nock-a-useful-tool"},{"type":"extras","title":"Dumping Types - Dumping","doc":"Types in Hoon are just functions!\n\nA good example can be found by looking at the resource-type\n\n```hoon\n> .*  resource:resource-machine  [0 2]\n[ 8\n  [ [8 [7 [0 7] 9 47 0 1] 9 2 10 [6 0 28] 0 2]\n    [6 [6 [3 0 26] [1 1] 1 0] [0 26] 0 0]\n    [6 [6 [3 0 54] [1 1] 1 0] [0 54] 0 0]\n    [6 [6 [3 0 110] [1 1] 1 0] [0 110] 0 0]\n    [6 [5 [1 0] 0 222] [1 0] 6 [5 [1 1] 0 222] [1 1] 0 0]\n    [6 [6 [3 0 446] [1 1] 1 0] [0 446] 0 0]\n    [6 [6 [3 0 894] [1 1] 1 0] [0 894] 0 0]\n    6\n    [6 [3 0 895] [1 1] 1 0]\n    [0 895]\n    0\n    0\n  ]\n  8\n  [5 [0 14] 0 2]\n  0\n  6\n]\n```\n\nThis however does not show how to dump the structure of a type well enough, however this can be fixed by simply just calling it!\n\n<!-- livebook:{\"break_markdown\":true} -->\n\ncalling a type leads to something like this\n\n```hoon\n> (resource:resource-machine)\n[   logic\n  < 1|xpg\n    [ [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n        proofs=it(#4)\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      [ roots=it(@)\n        commitments=it(@)\n        nullifiers=it(@)\n          proofs\n        it( ^#4\n          [   logic\n            < 1|xpg\n              [ [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                [ roots=it(@)\n                  commitments=it(@)\n                  nullifiers=it(@)\n                  proofs=it(#4)\n                  delta=it([denom=@ sign=?(%.y %.n) amount=@])\n                  extra=@\n                  preference=%~\n                ]\n                ?(%.y %.n)\n              ]\n            >\n            label=@t\n            quantity=@\n            data=@\n            eph=?(%.y %.n)\n            nonce=@\n            npk=@\n            rseed=@\n          ]\n        )\n        delta=it([denom=@ sign=?(%.y %.n) amount=@])\n        extra=@\n        preference=%~\n      ]\n      ?(%.y %.n)\n    ]\n  >\n  label=''\n  quantity=0\n  data=0\n  eph=%.y\n  nonce=0\n  npk=0\n  rseed=0\n]\n```\n\nWhich just gives the default values. If the result is hard to read, then no problem, just forget the type information!\n\n```\n> `*`(resource:resource-machine)\n[[[0 15] [0 0 0 0 0 0 0] [0 0 0 0 0 0 0] 0] 0 0 0 0 0 0 0]\n```\n\nHere we simply jsut cast it to the any type, forgetting all information, and we can now see the format of the empty resource.","ref":"dumping.html#dumping-types"},{"type":"extras","title":"Dump Modules - Dumping","doc":"Dumping modules is the same as dumping functions, it's just a matter that one's terminal will be flooded\n\n```hoon\n> .*  resource-machine  [0 2]\n[ [1 0]\n...\n  0\n  1\n]\n```\n\nThus feel free to dump away. This is only useful when trying to copy this to the Elixir codebase.","ref":"dumping.html#dump-modules"},{"type":"extras","title":"Dumping Hoon for Elixir - Dumping","doc":"Since Anoma itself runs Nock and not Hoon, we have to take the Hoon code we have and include it in Elixir somehow.\n\nThis process isn't particular difficult, and we can do it by simply using the tools we've learned in this document.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nFor example, it's not uncommon when the standard library that test indicies are not out of date and need to be updated, or maybe we define out a new hoon function for testing.\n\nIn these scenarios, there is a very easy way to update the code.\n\nLet us look at the fibonacci example in Elixir\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n# can be found in https://github.com/anoma/anoma/blob/base/lib/test_helper/nock.ex\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 255] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 255] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm, sample | logics_core()]\n  end\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nHere we have some just plain old nock string representing the function, and we append the context to it via normal Elixir. We do this to save space, as we really don't want to dump the entire `Nock.logics_core/0` for every simple function.\n\nOn the Hoon side we just run this to get the proper new logic\n\n```hoon\n> .*  fib:tests  [0 2]\n[ 8\n  [1 1 0]\n  8\n  [ 1\n    6\n    [5 [0 30] 1 0]\n    [0 13]\n    9\n    2\n    10\n    [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n    10\n    [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n    0\n    1\n  ]\n  9\n  2\n  0\n  1\n]\n```\n\nand then replace the old logic with the new code.\n\n<!-- livebook:{\"force_markdown\":true} -->\n\n```elixir\n  @spec factorial() :: Noun.t()\n  def factorial() do\n    arm = Noun.Format.parse_always(\"\n    [ 8\n      [1 1 0]\n      8\n      [ 1\n        6\n        [5 [0 30] 1 0]\n        [0 13]\n        9\n        2\n        10\n        [30 8 [9 342 0 1.023] 9 2 10 [6 0 62] 0 2]\n        10\n        [6 [8 [9 20 0 1.023] 9 2 10 [6 [0 29] 0 28] 0 2] 0 12]\n        0\n        1\n      ]\n      9\n      2\n      0\n      1\n    ]\")\n    sample = 1\n    [arm,, sample | logics_core()]\n  end\n```\n\nThe process is the same for the code in `Nock`, just dump the `[0 2]` index of the module and replace the string with the result you get in your terminal.","ref":"dumping.html#dumping-hoon-for-elixir"},{"type":"extras","title":"Dumping Indexing Offsets - Dumping","doc":"The tools that we have explored so far only deal with dumping definitions, however they do not explain where these functions are stored in the environment.\n\nThat is where [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) comes handy.\n\n[zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis) simply gives us the hoon expression of the argument handed to it.\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nLet us start off simple with [zaptis(!=)](https://developers.urbit.org/reference/hoon/rune/zap#-zaptis), let us look at what saying `anoma` actually does.\n\n```hoon\n> !=(anoma)\n[0 46]\n```\n\nInteresting, we can see that saying anoma, indexs into the current environment by `46`. The current environment in Hoon can be conjured with `.`.\n\n```hoon\n> !=(.)\n[0 1]\n```\n\nWith this knowledge in hand, we can verify that anoma really is at index 46!\n\n```hoon\n> =(.*(. [0 46]) anoma)\n%.y\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow that we know how to get the index for names like anoma, what about trying to get the index of a function like `dec` inside of the anoma environment.\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n> ;;  nock  !=(dec:anoma)\n[%7 p=[%0 p=46] q=[%9 p=342 q=[%0 p=15]]]\n```\n\nHere it's a bit more complicated to let us break it down step by step.\n\n1. `[%7 p=[%0 p=46] q=...]`\n   * In the section where we are calling `%7`.\n   * This has the effect of just trying to get anoma to be the subject of the following `q` computation.\n2. Now at `q=[%9 p=342 q=[%0 p=15]]` we are running this on anoma itself.\n   * `%9` is rather basic, trying to call the given index `p` at arm `q`.\n   * In our case, `dec` is located at index `342` inside of arm at the layer/module located at `[0 15]`.\n   * `[0 15]` is really layer 1 in the source code and is properly documented as such\n\n```hoon\n~%  %one  +  ~\n|%\n++  dec  ::  +342\n  ~/  %dec\n  |=  a=@\n  ?<  =(0 a)\n  =|  b=@\n  |-  ^-  @\n  ?:  =(a +(b))  b\n  $(b +(b))\n\n```\n\nThus, it's not very complicated, thus in the form\n\n```hoon\n> !=(dec:anoma)\n[7 [0 46] 9 342 0 15]\n```\n\nall we have to pay attention to is the `342` and the `15`, some more examples show this off well\n\n```hoon\n> !=(dec:anoma) ::  index 342 at layer 1\n[7 [0 46] 9 342 0 15]\n> !=(add:anoma) ::  index 20 at layer 1\n[7 [0 46] 9 20 0 15]\n> !=(trap:anoma) ::  index 20 at layer 2\n[7 [0 46] 9 20 0 7]\n> !=(unit:anoma) ::  index 42 at layer 2\n[7 [0 46] 9 42 0 7]\n```\n\nHere for any non nested module we can see the layers and indexs quite plainly!\n\n<!-- livebook:{\"branch_parent_index\":7} -->","ref":"dumping.html#dumping-indexing-offsets"},{"type":"extras","title":"How Index of Layers Change - Dumping","doc":"The hoon environment is a binary tree. Included below is an extended diagram that we will use for our explanation.\n\n```mermaid\nstateDiagram-v2\n1 --> 2\n1 --> 3\n3 --> 6\n3 --> 7\n7 --> 14\n7 --> 15\n15 --> 30\n15 --> 31\n```\n\nWhenever, a layer is made in hoon, we should think of it as pushed onto the env. So for Anoma the layers can be seen like this\n\n```mermaid\nstateDiagram-v2\nlayer_four --> code_in_layer_four\nlayer_four --> layer_three\nlayer_three --> code_in_layer_three\nlayer_three --> layer_two\nlayer_two --> code_in_layer_two\nlayer_two --> layer_one\nlayer_one --> code_in_layer_one\nlayer_one --> 0_3_99\n```\n\nIf we pushed layer 5, then everything shifts, layer 1 moves from 15 to 31.\n\nThus the indexing works on a rather simple formula that can be read about: [here](https://oeis.org/A000918). The code is not exactly this formula, but below we will show how it shapes up.\n\n```elixir\nseries = 1..5 |> Enum.map(fn i -> 2 ** i - 1 end)\nindicies = 1..5\nmy_data = %{series: series, indicies: indicies}\n```\n\n<!-- livebook:{\"output\":true} -->\n\n```\n%{series: [1, 3, 7, 15, 31], indicies: 1..5}\n```\n\n<!-- livebook:{\"attrs\":\"eyJjaGFydF90aXRsZSI6IkluZGV4aW5nIFNlcmllcyIsImhlaWdodCI6MzAwLCJsYXllcnMiOlt7ImFjdGl2ZSI6dHJ1ZSwiY2hhcnRfdHlwZSI6ImJhciIsImNvbG9yX2ZpZWxkIjpudWxsLCJjb2xvcl9maWVsZF9hZ2dyZWdhdGUiOm51bGwsImNvbG9yX2ZpZWxkX2JpbiI6bnVsbCwiY29sb3JfZmllbGRfc2NhbGVfc2NoZW1lIjpudWxsLCJjb2xvcl9maWVsZF90eXBlIjpudWxsLCJkYXRhX3ZhcmlhYmxlIjoibXlfZGF0YSIsImdlb2RhdGFfY29sb3IiOiJncmVlbiIsImxhdGl0dWRlX2ZpZWxkIjoiYSIsImxvbmdpdHVkZV9maWVsZCI6ImIiLCJ4X2ZpZWxkIjoiaW5kaWNpZXMiLCJ4X2ZpZWxkX2FnZ3JlZ2F0ZSI6bnVsbCwieF9maWVsZF9iaW4iOm51bGwsInhfZmllbGRfc2NhbGVfdHlwZSI6bnVsbCwieF9maWVsZF90eXBlIjoicXVhbnRpdGF0aXZlIiwieV9maWVsZCI6InNlcmllcyIsInlfZmllbGRfYWdncmVnYXRlIjpudWxsLCJ5X2ZpZWxkX2JpbiI6bnVsbCwieV9maWVsZF9zY2FsZV90eXBlIjpudWxsLCJ5X2ZpZWxkX3R5cGUiOiJxdWFudGl0YXRpdmUifV0sInZsX2FsaWFzIjoiRWxpeGlyLlZlZ2FMaXRlIiwid2lkdGgiOjIwMH0\",\"chunks\":null,\"kind\":\"Elixir.KinoVegaLite.ChartCell\",\"livebook_object\":\"smart_cell\"} -->\n\n```elixir\nVegaLite.new(width: 200, height: 300, title: \"Indexing Series\")\n|> VegaLite.data_from_values(my_data, only: [\"indicies\", \"series\"])\n|> VegaLite.mark(:bar)\n|> VegaLite.encode_field(:x, \"indicies\", type: :quantitative)\n|> VegaLite.encode_field(:y, \"series\", type: :quantitative)\n```","ref":"dumping.html#how-index-of-layers-change"},{"type":"extras","title":"Setting up Hoon","doc":"<!-- livebook:{\"persist_outputs\":true} -->\n\n# Setting up Hoon","ref":"setting-up.html"},{"type":"extras","title":"Index - Setting up Hoon","doc":"1. [Contributing](./../CONTRIBUTING.livemd)\n   1. [Git](./../contributing/git.livemd)\n   2. [Hoon](./../contributing/hoon.livemd)\n   3. [Iex](./../contributing/iex.livemd)\n   4. [Observer](./../contributing/observer.livemd)\n   5. [Testing](./../contributing/testing.livemd)\n      1. [Running Tests](./../contributing/testing/running-tests.livemd)\n      2. [Writing Tests](./../contributing/testing/writing-tests.livemd)\n   6. [Understanding](./../contributing/understanding.livemd)\n2. [Hoon](./../hoon.livemd)\n   1. [Calling](./../hoon/calling.livemd)\n   2. [Dumping](./../hoon/dumping.livemd)\n   3. [Setting Up](./../hoon/setting-up.livemd)\n3. [Index](./../index.livemd)\n4. [Index_docs](./../index_docs.livemd)\n5. [Visualization](./../visualization.livemd)\n   1. [Actors](./../visualization/actors.livemd)\n6. [Vm_interface](./../vm_interface.livemd)","ref":"setting-up.html#index"},{"type":"extras","title":"Getting a Good Hoon environment - Setting up Hoon","doc":"A good starting point is to read [Hoon's docs on environment](https://developers.urbit.org/guides/core/environment)\n\nIt's good to follow it until the section \"Mount a desk\"\n\nFrom here we can setup the environment quite nicely\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```hoon\n|merge %anoma our %base\n|mount %anoma\n```\n\nFrom here we want to remove all the uneeded files, get it to the following state:\n\n<!-- livebook:{\"break_markdown\":true} -->\n\n```bash\n8 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n├── mar\n│   ├── hoon.hoon\n│   ├── mime.hoon\n│   ├── noun.hoon\n│   ├── txt-diff.hoon\n│   └── txt.hoon\n└── sys.kelvin\n\n2 directories, 6 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nwith `sys.kelvin` having only `[%zuse 412]`\n\nNow that we have our minimal state, we can symlink in the files in\nhttps://github.com/anoma/anoma/tree/base/hoon\n\ninto `lib`. It should now look something like this\n\n```bash\n9 taichi@Gensokyo:~/Documents/Workspace/Hoon/zod git:master:? % tree anoma\nanoma\n├── lib\n│   ├── anoma.hoon -> .../hoon/anoma.hoon\n│   ├── logics.hoon -> .../hoon/logics.hoon\n│   ├── resource-machine.hoon -> .../hoon/resource-machine.hoon\n│   └── tests.hoon -> .../hoon/tests.hoon\n├── mar\n│   ├── hoon.hoon\n│   ├── mime.hoon\n│   ├── noun.hoon\n│   ├── txt-diff.hoon\n│   └── txt.hoon\n└── sys.kelvin\n\n3 directories, 10 files\n```\n\n<!-- livebook:{\"break_markdown\":true} -->\n\nNow we can mount our anoma code into hoon\n\n```hoon\n> |commit %anoma\n>=\n> =anoma /=anoma=/lib/anoma/hoon\n> =resource-machine -build-file /=anoma=/lib/resource-machine/hoon\n> =logics -build-file /=anoma=/lib/logics/hoon\n> =tests -build-file /=anoma=/lib/tests/hoon\n```\n\nFrom here, the hoon environment is ready to be used and it should work just as Anoma uses Nock.","ref":"setting-up.html#getting-a-good-hoon-environment"}],"content_type":"text/markdown"}